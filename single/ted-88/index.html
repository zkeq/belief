<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<link rel="shortcut icon" href="/favicon.ico">
<meta name="referrer" content="no-referrer">
<script src="/yinghua/Ascii.js"></script>
<script src="/dplayer/dplayer.js"></script>
<link rel="stylesheet" href="/css/daily.css">

<title>【TED】我们可以建造AI，而不会失去对它的控制吗？</title>
</head>
<body class='typora-export os-windows'><div class='typora-export-content'>
<div id='write'  class=''><blockquote><p><span>声明: 本站全部内容源自互联网,不进行任何盈利行为</span></p><p><strong><span>仅做 整合 / 美化 处理</span></strong></p><p><span>首页: </span><a href='https://dream-plan.cn' target='_blank' class='url'>https://dream-plan.cn</a><span> </span></p></blockquote><h2 id='title'><span>【TED】我们可以建造AI，而不会失去对它的控制吗？</span></h2><div id="play"></div>
<script>
const play = new DPlayer({
    container: document.getElementById('play'),
    theme:'#c61e07',
    preload:'none',
    video: {
        pic:'https://s-bj-2220-zkeq.oss.dogecdn.com/head.jpg',
        url: 'https://mov.bn.netease.com/open-movie/nos/mp4/2021/09/15/SGJ0S2878_shd.mp4'
    },
    subtitle: {
        url:'https://s-bj-2220-open-srt.oss.dogecdn.com/88.vtt',
        fontSize: '25px',
    },
});
</script><p>&nbsp;</p><p><code>I'm going to talk about a failure of intuition</code>
<span>我想谈论一种我们 很多人都经历过的</span>
<code>that many of us suffer from.</code>
<span>来自于直觉上的失误。</span>
<code>It's really a failure to detect a certain kind of danger.</code>
<span>它让人们无法察觉到 一种特定危险的存在。</span>
<code>I'm going to describe a scenario</code>
<span>我要向大家描述一个情景，</span>
<code>that I think is both terrifying</code>
<span>一个我觉得既令人害怕，</span>
<code>and likely to occur,</code>
<span>却又很可能发生的情景。</span>
<code>and that's not a good combination,</code>
<span>这样一个组合的出现，</span>
<code>as it turns out.</code>
<span>显然不是一个好的征兆。</span>
<code>And yet rather than be scared, most of you will feel</code>
<span>不过，在座的大部分人都会觉得，</span>
<code>that what I'm talking about is kind of cool.</code>
<span>我要谈论的这件事其实挺酷的。</span>
<code>I'm going to describe how the gains we make</code>
<span>我将描述我们从人工智能中</span>
<code>in artificial intelligence</code>
<span>获得的好处，</span>
<code>could ultimately destroy us.</code>
<span>将怎样彻底地毁灭我们。</span>
<code>And in fact, I think it's very difficult to see how they won't destroy us</code>
<span>事实上，想看到人工智能 最终不摧毁我们是很难的，</span>
<code>or inspire us to destroy ourselves.</code>
<span>或者说它必将驱使我们自我毁灭。</span>
<code>And yet if you're anything like me,</code>
<span>如果你和我有共同点，</span>
<code>you'll find that it's fun to think about these things.</code>
<span>你会发现思考这些问题 是相当有趣的。</span>
<code>And that response is part of the problem.</code>
<span>而这种反应就是问题的一部分。</span>
<code>OK? That response should worry you.</code>
<span>因为这种想法应该使你感到担忧。</span>
<code>And if I were to convince you in this talk</code>
<span>假如我想在这个演讲中让你们相信，</span>
<code>that we were likely to suffer a global famine,</code>
<span>我们因为气候变化或者其他灾难，</span>
<code>either because of climate change or some other catastrophe,</code>
<span>很可能会遭受全球性的饥荒，</span>
<code>and that your grandchildren, or their grandchildren,</code>
<span>同时，你们的子孙后辈</span>
<code>are very likely to live like this,</code>
<span>都可能在这样的饥荒中挣扎求生，</span>
<code>you wouldn't think,</code>
<span>你们就不会觉得</span>
<code>"Interesting.</code>
<span>“真有趣，</span>
<code>I like this TED Talk."</code>
<span>我喜欢这个TED演讲。”</span>
<code>Famine isn't fun.</code>
<span>因为饥荒一点都不有趣。</span>
<code>Death by science fiction, on the other hand, is fun,</code>
<span>不过，科幻小说中的死亡 往往却引人入胜。</span>
<code>and one of the things that worries me most about the development of AI at this point</code>
<span>所以我现在最担心的一个问题是，</span>
<code>is that we seem unable to marshal an appropriate emotional response</code>
<span>人们对人工智能的发展将带来的危险，</span>
<code>to the dangers that lie ahead.</code>
<span>似乎还没有形成一个正确的认识。</span>
<code>I am unable to marshal this response, and I'm giving this talk.</code>
<span>我也同样如此，所以我想 在这个演讲中和大家一起探讨。</span>
<code>It's as though we stand before two doors.</code>
<span>我们就像站在了两扇门前。</span>
<code>Behind door number one,</code>
<span>在第一扇门后面，</span>
<code>we stop making progress in building intelligent machines.</code>
<span>我们停下打造智能机器的脚步。</span>
<code>Our computer hardware and software just stops getting better for some reason.</code>
<span>某些原因也使我们停止了 对电脑软件和硬件的升级。</span>
<code>Now take a moment to consider why this might happen.</code>
<span>现在让我们想一下为什么会这样。</span>
<code>I mean, given how valuable intelligence and automation are,</code>
<span>我的意思是，当我们认识到 智能和自动化不可估量的价值时，</span>
<code>we will continue to improve our technology if we are at all able to.</code>
<span>我们总会竭尽所能的改善这些科技。</span>
<code>What could stop us from doing this?</code>
<span>那么，什么会使我们停下脚步呢？</span>
<code>A full-scale nuclear war?</code>
<span>一场大规模的核战争？</span>
<code>A global pandemic?</code>
<span>一次全球性的瘟疫？</span>
<code>An asteroid impact?</code>
<span>一个小行星撞击了地球？</span>
<code>Justin Bieber becoming president of the United States?</code>
<span>或者是贾斯汀·比伯成为了美国总统？</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>The point is, something would have to destroy civilization as we know it.</code>
<span>重点是，总有一个事物 会摧毁人类现有的文明。</span>
<code>You have to imagine how bad it would have to be</code>
<span>你需要思考这个灾难究竟有多恐怖，</span>
<code>to prevent us from making improvements in our technology</code>
<span>才会永久性地阻止我们</span>
<code>permanently,</code>
<span>发展科技，</span>
<code>generation after generation.</code>
<span>永久性的。</span>
<code>Almost by definition, this is the worst thing</code>
<span>光想想它， 就觉得这将是人类历史上</span>
<code>that's ever happened in human history.</code>
<span>能发生的最惨绝人寰的事了。</span>
<code>So the only alternative,</code>
<span>那么，我们唯一剩下的选择，</span>
<code>and this is what lies behind door number two,</code>
<span>就藏在第二扇门的后面，</span>
<code>is that we continue to improve our intelligent machines</code>
<span>那就是我们持续 改进我们的智能机器，</span>
<code>year after year after year.</code>
<span>永不停歇。</span>
<code>At a certain point, we will build machines that are smarter than we are,</code>
<span>在将来的某一天，我们会 造出比我们更聪明的机器，</span>
<code>and once we have machines that are smarter than we are,</code>
<span>一旦我们有了 比我们更聪明的机器，</span>
<code>they will begin to improve themselves.</code>
<span>它们将进行自我改进。</span>
<code>And then we risk what the mathematician IJ Good called</code>
<span>然后我们就会承担着 数学家IJ Good 所说的</span>
<code>an "intelligence explosion,"</code>
<span>“智能爆炸”的风险，</span>
<code>that the process could get away from us.</code>
<span>（科技进步的） 进程将不再受我们的控制。</span>
<code>Now, this is often caricatured, as I have here,</code>
<span>现在我们时常会看到 这样一些讽刺漫画，</span>
<code>as a fear that armies of malicious robots</code>
<span>我们总会担心受到一些不怀好意的</span>
<code>will attack us.</code>
<span>机器人军队的攻击。</span>
<code>But that isn't the most likely scenario.</code>
<span>但这不是最可能出现的事情。</span>
<code>It's not that our machines will become spontaneously malevolent.</code>
<span>我们的机器不会自动变得邪恶。</span>
<code>The concern is really that we will build machines</code>
<span>所以，我们唯一的顾虑就是 我们将会打造</span>
<code>that are so much more competent than we are</code>
<span>比我们人类更有竞争力的机器。</span>
<code>that the slightest divergence between their goals and our own</code>
<span>而一旦我们和它们的目标不一致，</span>
<code>could destroy us.</code>
<span>我们将会被摧毁。</span>
<code>Just think about how we relate to ants.</code>
<span>想想我们与蚂蚁的关系吧。</span>
<code>We don't hate them.</code>
<span>我们不讨厌它们，</span>
<code>We don't go out of our way to harm them.</code>
<span>我们不会去主动去伤害它们。</span>
<code>In fact, sometimes we take pains not to harm them.</code>
<span>实际上，我们经常会尽量 避免伤害蚂蚁。</span>
<code>We step over them on the sidewalk.</code>
<span>我们会选择从它们身边走过。</span>
<code>But whenever their presence</code>
<span>但只要它们的存在</span>
<code>seriously conflicts with one of our goals,</code>
<span>妨碍到了我们达成目标，</span>
<code>let's say when constructing a building like this one,</code>
<span>比如说当我们在建造这样一个建筑，</span>
<code>we annihilate them without a qualm.</code>
<span>我们会毫不手软地杀掉它们。</span>
<code>The concern is that we will one day build machines</code>
<span>所以我们的顾虑是，终将有一天 我们打造的机器，</span>
<code>that, whether they're conscious or not,</code>
<span>不管它们是否有意识， 它们终将会以</span>
<code>could treat us with similar disregard.</code>
<span>我们对待蚂蚁的方式 来对待我们。</span>
<code>Now, I suspect this seems far-fetched to many of you.</code>
<span>我想很多人会说这很遥远。</span>
<code>I bet there are those of you who doubt that superintelligent AI is possible,</code>
<span>我打赌你们中有些人还会 怀疑超级人工智能是否可能实现，</span>
<code>much less inevitable.</code>
<span>认为我是在小题大做。</span>
<code>But then you must find something wrong with one of the following assumptions.</code>
<span>但是你很快会发现以下这些 假设中的某一个是有问题的。</span>
<code>And there are only three of them.</code>
<span>下面是仅有的三种假设：</span>
<code>Intelligence is a matter of information processing in physical systems.</code>
<span>第一，智慧可以被看做 物理系统中的信息处理过程。</span>
<code>Actually, this is a little bit more than an assumption.</code>
<span>事实上，这不仅仅是一个假设。</span>
<code>We have already built narrow intelligence into our machines,</code>
<span>我们已经在有些机器中 嵌入了智能系统，</span>
<code>and many of these machines perform</code>
<span>这些机器中很多已经</span>
<code>at a level of superhuman intelligence already.</code>
<span>有着超越普通人的智慧了。</span>
<code>And we know that mere matter</code>
<span>而且，我们也知道任何一点小事</span>
<code>can give rise to what is called "general intelligence,"</code>
<span>都可以引发所谓的“普遍智慧”，</span>
<code>an ability to think flexibly across multiple domains,</code>
<span>这是一种可以在不同领域间 灵活思考的能力，</span>
<code>because our brains have managed it. Right?</code>
<span>因为我们的大脑已经 成功做到了这些。对吧？</span>
<code>I mean, there's just atoms in here,</code>
<span>我的意思是， 大脑里其实都是原子，</span>
<code>and as long as we continue to build systems of atoms</code>
<span>只要我们继续建造这些原子体系，</span>
<code>that display more and more intelligent behavior,</code>
<span>我们就能实现越来越多的智慧行为，</span>
<code>we will eventually, unless we are interrupted,</code>
<span>我们最终将会， 当然除非我们被干扰，</span>
<code>we will eventually build general intelligence</code>
<span>我们最终将会给我们的机器赋予</span>
<code>into our machines.</code>
<span>广泛意义上的智能。</span>
<code>It's crucial to realize that the rate of progress doesn't matter,</code>
<span>我们要知道这个进程的速度并不重要，</span>
<code>because any progress is enough to get us into the end zone.</code>
<span>因为任何进程都足够 让我们走进死胡同。</span>
<code>We don't need Moore's law to continue. We don't need exponential progress.</code>
<span>甚至不需要考虑摩尔定律， 也不需要用指数函数来衡量，</span>
<code>We just need to keep going.</code>
<span>这一切顺其自然都会发生。</span>
<code>The second assumption is that we will keep going.</code>
<span>第二个假设是，我们会一直创新。</span>
<code>We will continue to improve our intelligent machines.</code>
<span>去继续改进我们的智能机器。</span>
<code>And given the value of intelligence --</code>
<span>由于智慧的价值就是——</span>
<code>I mean, intelligence is either the source of everything we value</code>
<span>提供我们所珍爱的事物，</span>
<code>or we need it to safeguard everything we value.</code>
<span>或是用于保护我们所珍视的一切。</span>
<code>It is our most valuable resource.</code>
<span>智慧就是我们最有价值的资源。</span>
<code>So we want to do this.</code>
<span>所以我们想继续革新它。</span>
<code>We have problems that we desperately need to solve.</code>
<span>因为我们有很多需要 迫切解决的问题。</span>
<code>We want to cure diseases like Alzheimer's and cancer.</code>
<span>我们想要治愈像阿兹海默症 和癌症这样的疾病，</span>
<code>We want to understand economic systems. We want to improve our climate science.</code>
<span>我们想要了解经济系统， 想要改善我们的气候科学，</span>
<code>So we will do this, if we can.</code>
<span>所以只要可能， 我们就会将革新继续下去。</span>
<code>The train is already out of the station, and there's no brake to pull.</code>
<span>而且革新的列车早已驶出，  车上却没有刹车。</span>
<code>Finally, we don't stand on a peak of intelligence,</code>
<span>第三种假设是： 人类没有登上智慧的巅峰，</span>
<code>or anywhere near it, likely.</code>
<span>甚至连接近可能都谈不上。</span>
<code>And this really is the crucial insight.</code>
<span>这个想法十分关键。</span>
<code>This is what makes our situation so precarious,</code>
<span>这就是为什么 我们所处的环境是很危险的，</span>
<code>and this is what makes our intuitions about risk so unreliable.</code>
<span>这也是为什么我们对风险的 直觉是不可靠的。</span>
<code>Now, just consider the smartest person who has ever lived.</code>
<span>现在，请大家想一下 谁是世界上最聪明的人。</span>
<code>On almost everyone's shortlist here is John von Neumann.</code>
<span>几乎每个人的候选名单里都会 有约翰·冯·诺伊曼。</span>
<code>I mean, the impression that von Neumann made on the people around him,</code>
<span>冯·诺伊曼留给周围人的印象</span>
<code>and this included the greatest mathematicians and physicists of his time,</code>
<span>就是他是那个时代当中最杰出的 数学家和物理学家，</span>
<code>is fairly well-documented.</code>
<span>这些都是完好的记录在案的。</span>
<code>If only half the stories about him are half true,</code>
<span>即使他的故事里有一半是假的，</span>
<code>there's no question</code>
<span>都没有人会质疑</span>
<code>he's one of the smartest people who has ever lived.</code>
<span>他仍然是世界上最聪明的人之一。</span>
<code>So consider the spectrum of intelligence.</code>
<span>那么，让我们来看看智慧谱线吧。</span>
<code>Here we have John von Neumann.</code>
<span>现在我们有了约翰·冯·诺伊曼，</span>
<code>And then we have you and me.</code>
<span>还有我们大家。</span>
<code>And then we have a chicken.</code>
<span>另外还有一只鸡。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>Sorry, a chicken.</code>
<span>抱歉，母鸡的位置应该在这。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>There's no reason for me to make this talk more depressing than it needs to be.</code>
<span>这个演讲已经够严肃了， 开个玩笑轻松一下。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>It seems overwhelmingly likely, however, that the spectrum of intelligence</code>
<span>然而，很可能的情况是， 智慧谱线上的内容</span>
<code>extends much further than we currently conceive,</code>
<span>已远远超出了我们的认知，</span>
<code>and if we build machines that are more intelligent than we are,</code>
<span>如果我们建造了比 自身更聪明的机器，</span>
<code>they will very likely explore this spectrum</code>
<span>它们将非常可能 以超乎寻常的方式</span>
<code>in ways that we can't imagine,</code>
<span>延展这个谱线，</span>
<code>and exceed us in ways that we can't imagine.</code>
<span>最终超越人类。</span>
<code>And it's important to recognize that this is true by virtue of speed alone.</code>
<span>仅仅从速度方面考虑， 我们就能够意识到这一点。</span>
<code>Right? So imagine if we just built a superintelligent AI</code>
<span>那么，现在让我们来想象一下 我们刚建好一个超级人工智能机器，</span>
<code>that was no smarter than your average team of researchers</code>
<span>大概和斯坦福 或是麻省理工学院的研究员的</span>
<code>at Stanford or MIT.</code>
<span>平均水平差不多吧。</span>
<code>Well, electronic circuits function about a million times faster</code>
<span>但是，电路板要比生物系统</span>
<code>than biochemical ones,</code>
<span>运行速度快一百万倍，</span>
<code>so this machine should think about a million times faster</code>
<span>所以这个机器思考起来 会比那些打造它的大脑</span>
<code>than the minds that built it.</code>
<span>快一百万倍。</span>
<code>So you set it running for a week,</code>
<span>当你让它运行一周后，</span>
<code>and it will perform 20,000 years of human-level intellectual work,</code>
<span>它将能呈现出相当于人类智慧在 20000年间发展出的水平，</span>
<code>week after week after week.</code>
<span>而这个过程将周而复始。</span>
<code>How could we even understand, much less constrain,</code>
<span>那么，我们又怎么能理解， 更不用说去制约</span>
<code>a mind making this sort of progress?</code>
<span>一个以如此速度运行的机器呢？</span>
<code>The other thing that's worrying, frankly,</code>
<span>坦白讲，另一件令人担心的事就是，</span>
<code>is that, imagine the best case scenario.</code>
<span>我们考虑一下最理想的情景。</span>
<code>So imagine we hit upon a design of superintelligent AI</code>
<span>想象我们正好做出了 一个没有任何安全隐患的</span>
<code>that has no safety concerns.</code>
<span>超级人工智能。</span>
<code>We have the perfect design the first time around.</code>
<span>我们有了一个前所未有的完美设计。</span>
<code>It's as though we've been handed an oracle</code>
<span>就好像我们被赐予了一件神物，</span>
<code>that behaves exactly as intended.</code>
<span>它能够准确的执行目标动作。</span>
<code>Well, this machine would be the perfect labor-saving device.</code>
<span>这个机器将完美的节省人力工作。</span>
<code>It can design the machine that can build the machine</code>
<span>它设计出的机器 能够再生产其他机器，</span>
<code>that can do any physical work,</code>
<span>去完成所有的人力工作。</span>
<code>powered by sunlight,</code>
<span>由太阳能供电，</span>
<code>more or less for the cost of raw materials.</code>
<span>而成本的多少仅取决于原材料。</span>
<code>So we're talking about the end of human drudgery.</code>
<span>那么，我们正在谈论的 就是人力劳动的终结。</span>
<code>We're also talking about the end of most intellectual work.</code>
<span>也关乎脑力劳动的终结。</span>
<code>So what would apes like ourselves do in this circumstance?</code>
<span>那在这种情况下， 像我们这样的"大猩猩"还能有什么用呢？</span>
<code>Well, we'd be free to play Frisbee and give each other massages.</code>
<span>我们可以悠闲地玩飞盘， 给彼此做按摩。</span>
<code>Add some LSD and some questionable wardrobe choices,</code>
<span>服用一些迷药， 穿一些奇装异服，</span>
<code>and the whole world could be like Burning Man.</code>
<span>整个世界都沉浸在狂欢节之中。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>Now, that might sound pretty good,</code>
<span>那可能听起来挺棒的，</span>
<code>but ask yourself what would happen</code>
<span>不过让我们扪心自问，</span>
<code>under our current economic and political order?</code>
<span>在现有的经济和政治体制下， 这意味着什么？</span>
<code>It seems likely that we would witness</code>
<span>我们很可能会目睹</span>
<code>a level of wealth inequality and unemployment</code>
<span>前所未有的贫富差距</span>
<code>that we have never seen before.</code>
<span>和失业率。</span>
<code>Absent a willingness to immediately put this new wealth</code>
<span>有钱人不愿意马上把这笔新的财富</span>
<code>to the service of all humanity,</code>
<span>贡献出来服务社会，</span>
<code>a few trillionaires could grace the covers of our business magazines</code>
<span>这时一些千万富翁能够优雅地 登上商业杂志的封面，</span>
<code>while the rest of the world would be free to starve.</code>
<span>而剩下的人可能都在挨饿。</span>
<code>And what would the Russians or the Chinese do</code>
<span>如果听说硅谷里的公司</span>
<code>if they heard that some company in Silicon Valley</code>
<span>即将造出超级人工智能，</span>
<code>was about to deploy a superintelligent AI?</code>
<span>俄国人和中国人 会采取怎样的行动呢？</span>
<code>This machine would be capable of waging war,</code>
<span>那个机器将能够 以一种前所未有的能力</span>
<code>whether terrestrial or cyber,</code>
<span>去开展由领土问题和</span>
<code>with unprecedented power.</code>
<span>网络问题引发的战争。</span>
<code>This is a winner-take-all scenario.</code>
<span>这是一个胜者为王的世界。</span>
<code>To be six months ahead of the competition here</code>
<span>机器世界中的半年，</span>
<code>is to be 500,000 years ahead,</code>
<span>在现实世界至少会相当于</span>
<code>at a minimum.</code>
<span>50万年。</span>
<code>So it seems that even mere rumors of this kind of breakthrough</code>
<span>所以仅仅是关于这种科技突破的传闻，</span>
<code>could cause our species to go berserk.</code>
<span>就可以让我们的种族丧失理智。</span>
<code>Now, one of the most frightening things,</code>
<span>在我的观念里，</span>
<code>in my view, at this moment,</code>
<span>当前最可怕的东西</span>
<code>are the kinds of things that AI researchers say</code>
<span>正是人工智能的研究人员</span>
<code>when they want to be reassuring.</code>
<span>安慰我们的那些话。</span>
<code>And the most common reason we're told not to worry is time.</code>
<span>最常见的理由就是关于时间。</span>
<code>This is all a long way off, don't you know.</code>
<span>他们会说，现在开始担心还为时尚早。</span>
<code>This is probably 50 or 100 years away.</code>
<span>这很可能是50年或者 100年之后才需要担心的事。</span>
<code>One researcher has said,</code>
<span>一个研究人员曾说过，</span>
<code>"Worrying about AI safety</code>
<span>“担心人工智能的安全性</span>
<code>is like worrying about overpopulation on Mars."</code>
<span>就好比担心火星上人口过多一样。”</span>
<code>This is the Silicon Valley version</code>
<span>这就是硅谷版本的</span>
<code>of "don't worry your pretty little head about it."</code>
<span>“不要杞人忧天。”</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>No one seems to notice</code>
<span>似乎没有人注意到</span>
<code>that referencing the time horizon</code>
<span>以时间作为参考系</span>
<code>is a total non sequitur.</code>
<span>是得不出合理的结论的。</span>
<code>If intelligence is just a matter of information processing,</code>
<span>如果说智慧只包括信息处理，</span>
<code>and we continue to improve our machines,</code>
<span>然后我们继续改善这些机器，</span>
<code>we will produce some form of superintelligence.</code>
<span>那么我们终将生产出超级智能。</span>
<code>And we have no idea how long it will take us</code>
<span>但是，我们无法预估将花费多长时间</span>
<code>to create the conditions to do that safely.</code>
<span>来创造实现这一切的安全环境。</span>
<code>Let me say that again.</code>
<span>我再重复一遍。</span>
<code>We have no idea how long it will take us</code>
<span>我们无法预估将花费多长时间</span>
<code>to create the conditions to do that safely.</code>
<span>来创造实现这一切的安全环境。</span>
<code>And if you haven't noticed, 50 years is not what it used to be.</code>
<span>你们可能没有注意过， 50年的概念已今非昔比。</span>
<code>This is 50 years in months.</code>
<span>这是用月来衡量50年的样子。 （每个点表示一个月）</span>
<code>This is how long we've had the iPhone.</code>
<span>红色的点是代表苹果手机出现的时间。</span>
<code>This is how long "The Simpsons" has been on television.</code>
<span>这是《辛普森一家》（动画片） 在电视上播出以来的时间。</span>
<code>Fifty years is not that much time</code>
<span>要做好准备面对 人类历史上前所未有的挑战，</span>
<code>to meet one of the greatest challenges our species will ever face.</code>
<span>50年时间并不是很长。</span>
<code>Once again, we seem to be failing to have an appropriate emotional response</code>
<span>就像我刚才说的， 我们对确定会来临的事情</span>
<code>to what we have every reason to believe is coming.</code>
<span>做出了不合理的回应。</span>
<code>The computer scientist Stuart Russell has a nice analogy here.</code>
<span>计算机科学家斯图尔特·罗素 给出了一个极好的类比。</span>
<code>He said, imagine that we received a message from an alien civilization,</code>
<span>他说，想象我们从 外太空接收到一条讯息，</span>
<code>which read:</code>
<span>上面写着：</span>
<code>"People of Earth,</code>
<span>“地球上的人类，</span>
<code>we will arrive on your planet in 50 years.</code>
<span>我们将在五十年后到达你们的星球，</span>
<code>Get ready."</code>
<span>做好准备吧。”</span>
<code>And now we're just counting down the months until the mothership lands?</code>
<span>于是我们就开始倒计时， 直到它们的“母舰”着陆吗？</span>
<code>We would feel a little more urgency than we do.</code>
<span>在这种情况下我们会感到更紧迫。</span>
<code>Another reason we're told not to worry</code>
<span>另外一个试图安慰我们的理由是，</span>
<code>is that these machines can't help but share our values</code>
<span>那些机器必须 拥有和我们一样的价值观，</span>
<code>because they will be literally extensions of ourselves.</code>
<span>因为它们将会是我们自身的延伸。</span>
<code>They'll be grafted onto our brains,</code>
<span>它们将会被嫁接到我们的大脑上，</span>
<code>and we'll essentially become their limbic systems.</code>
<span>我们将会成它们的边缘系统。</span>
<code>Now take a moment to consider</code>
<span>现在我们再思考一下</span>
<code>that the safest and only prudent path forward,</code>
<span>最安全的，也是唯一经慎重考虑后</span>
<code>recommended,</code>
<span>推荐的发展方向，</span>
<code>is to implant this technology directly into our brains.</code>
<span>是将这项技术直接植入我们大脑。</span>
<code>Now, this may in fact be the safest and only prudent path forward,</code>
<span>这也许确实是最安全的， 也是唯一慎重的发展方向，</span>
<code>but usually one's safety concerns about a technology</code>
<span>但通常在我们把它塞进脑袋之前，</span>
<code>have to be pretty much worked out before you stick it inside your head.</code>
<span>会充分考虑这项技术的安全性。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>The deeper problem is that building superintelligent AI on its own</code>
<span>更深一层的问题是： 仅仅制造出超级人工智能机器</span>
<code>seems likely to be easier</code>
<span>可能要比</span>
<code>than building superintelligent AI</code>
<span>既制造超级人工智能，</span>
<code>and having the completed neuroscience</code>
<span>又让其拥有能让 我们的思想和超级人工智能</span>
<code>that allows us to seamlessly integrate our minds with it.</code>
<span>无缝对接的完整的 神经科学系统要简单很多。</span>
<code>And given that the companies and governments doing this work</code>
<span>而做这些研究的公司或政府，</span>
<code>are likely to perceive themselves as being in a race against all others,</code>
<span>很可能将彼此视作竞争对手，</span>
<code>given that to win this race is to win the world,</code>
<span>因为赢得了比赛就意味着称霸了世界，</span>
<code>provided you don't destroy it in the next moment,</code>
<span>前提是不在刚成功后就将其销毁，</span>
<code>then it seems likely that whatever is easier to do</code>
<span>所以结论是：简单的选项</span>
<code>will get done first.</code>
<span>一定会被先实现。</span>
<code>Now, unfortunately, I don't have a solution to this problem,</code>
<span>但很遗憾， 除了建议更多人去思考这个问题，</span>
<code>apart from recommending that more of us think about it.</code>
<span>我对此并无解决方案。</span>
<code>I think we need something like a Manhattan Project</code>
<span>我觉得在人工智能问题上，</span>
<code>on the topic of artificial intelligence.</code>
<span>我们需要一个“曼哈顿计划” （二战核武器研究计划），</span>
<code>Not to build it, because I think we'll inevitably do that,</code>
<span>不是用于讨论如何制造人工智能， 因为我们一定会这么做，</span>
<code>but to understand how to avoid an arms race</code>
<span>而是去避免军备竞赛，</span>
<code>and to build it in a way that is aligned with our interests.</code>
<span>最终以一种有利于 我们的方式去打造它。</span>
<code>When you're talking about superintelligent AI</code>
<span>当你在谈论一个可以自我改造的</span>
<code>that can make changes to itself,</code>
<span>超级人工智能时，</span>
<code>it seems that we only have one chance to get the initial conditions right,</code>
<span>我们似乎只有 一次正确搭建初始系统的机会，</span>
<code>and even then we will need to absorb</code>
<span>而这个正确的初始系统</span>
<code>the economic and political consequences of getting them right.</code>
<span>需要我们在经济以及政治上 做出很大的努力。</span>
<code>But the moment we admit</code>
<span>但是当我们承认</span>
<code>that information processing is the source of intelligence,</code>
<span>信息处理是智慧的源头，</span>
<code>that some appropriate computational system is what the basis of intelligence is,</code>
<span>承认一些电脑系统是智能的基础，</span>
<code>and we admit that we will improve these systems continuously,</code>
<span>承认我们会不断改善这些系统，</span>
<code>and we admit that the horizon of cognition very likely far exceeds</code>
<span>承认我们现存的认知远没有达到极限，</span>
<code>what we currently know,</code>
<span>将很可能被超越，</span>
<code>then we have to admit</code>
<span>我们又必须同时承认</span>
<code>that we are in the process of building some sort of god.</code>
<span>我们在某种意义上 正在创造一个新的“上帝”。</span>
<code>Now would be a good time</code>
<span>现在正是思考人类是否</span>
<code>to make sure it's a god we can live with.</code>
<span>能与这个“上帝”和睦相处的最佳时机。</span>
<code>Thank you very much.</code>
<span>非常感谢！</span>
<code>(Applause)</code>
<span>（掌声）</span></p><center><a style="color: rgb(254,17,130)" href="https://icp.gov.moe/?keyword=20223985" target="_blank">萌ICP备20223985号</a></center></div></div>
</body>
</html>