<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<link rel="shortcut icon" href="/favicon.ico">
<meta name="referrer" content="no-referrer">
<script src="/yinghua/Ascii.js"></script>
<script src="/dplayer/dplayer.js"></script>
<link rel="stylesheet" href="/css/daily.css">

<title>【TED】盲目信仰大数据的时代必须结束</title>
</head>
<body class='typora-export os-windows'><div class='typora-export-content'>
<div id='write'  class=''><blockquote><p><span>声明: 本站全部内容源自互联网,不进行任何盈利行为</span></p><p><strong><span>仅做 整合 / 美化 处理</span></strong></p><p><span>首页: </span><a href='https://belief.zkeq.xyz' target='_blank' class='url'>https://belief.zkeq.xyz</a><span> </span></p></blockquote><h2 id='title'><span>【TED】盲目信仰大数据的时代必须结束</span></h2><div id="play"></div>
<script>
const play = new DPlayer({
    container: document.getElementById('play'),
    theme:'#c61e07',
    preload:'none',
    video: {
        pic:'https://s-bj-2220-zkeq.oss.dogecdn.com/head.jpg',
        url: 'https://mov.bn.netease.com/open-movie/nos/mp4/2021/07/28/SGF3C4QR3_shd.mp4'
    },
    subtitle: {
        url:'https://s-bj-2220-open-srt.oss.dogecdn.com/198.vtt',
        fontSize: '25px',
    },
});
</script><p>&nbsp;</p><p><code>Algorithms are everywhere.</code>
<span>算法无处不在。</span>
<code>They sort and separate the winners from the losers.</code>
<span>他们把成功者和失败者区分开来。</span>
<code>The winners get the job</code>
<span>成功者得到工作</span>
<code>or a good credit card offer.</code>
<span>或是一个很好的信用卡优惠计划。</span>
<code>The losers don't even get an interview</code>
<span>失败者甚至连面试机会都没有，</span>
<code>or they pay more for insurance.</code>
<span>或者要为保险付更多的钱。</span>
<code>We're being scored with secret formulas that we don't understand</code>
<span>我们被不理解的秘密公式打分，</span>
<code>that often don't have systems of appeal.</code>
<span>却并没有上诉的渠道。</span>
<code>That begs the question:</code>
<span>这引出了一个问题：</span>
<code>What if the algorithms are wrong?</code>
<span>如果算法是错误的怎么办？</span>
<code>To build an algorithm you need two things:</code>
<span>构建一个算法需要两个要素：</span>
<code>you need data, what happened in the past,</code>
<span>需要数据，如过去发生的事情，</span>
<code>and a definition of success,</code>
<span>和成功的定义，</span>
<code>the thing you're looking for and often hoping for.</code>
<span>你正在寻找的，通常希望得到的东西。</span>
<code>You train an algorithm by looking, figuring out.</code>
<span>你可以通过观察，理解来训练算法。</span>
<code>The algorithm figures out what is associated with success.</code>
<span>这种算法能找出与成功相关的因素。</span>
<code>What situation leads to success?</code>
<span>什么情况意味着成功？</span>
<code>Actually, everyone uses algorithms.</code>
<span>其实，每个人都使用算法。</span>
<code>They just don't formalize them in written code.</code>
<span>他们只是没有把它们写成书面代码。</span>
<code>Let me give you an example.</code>
<span>举个例子。</span>
<code>I use an algorithm every day to make a meal for my family.</code>
<span>我每天都用一种算法来 为我的家人做饭。</span>
<code>The data I use</code>
<span>我使用的数据</span>
<code>is the ingredients in my kitchen,</code>
<span>就是我厨房里的原料，</span>
<code>the time I have,</code>
<span>我拥有的时间，</span>
<code>the ambition I have,</code>
<span>我的热情，</span>
<code>and I curate that data.</code>
<span>然后我整理了这些数据。</span>
<code>I don't count those little packages of ramen noodles as food.</code>
<span>我不把那种小包拉面算作食物。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>My definition of success is:</code>
<span>我对成功的定义是：</span>
<code>a meal is successful if my kids eat vegetables.</code>
<span>如果我的孩子们肯吃蔬菜， 这顿饭就是成功的。</span>
<code>It's very different from if my youngest son were in charge.</code>
<span>这和我最小的儿子 负责做饭时的情况有所不同。</span>
<code>He'd say success is if he gets to eat lots of Nutella.</code>
<span>他说，如果他能吃很多 Nutella巧克力榛子酱就是成功。</span>
<code>But I get to choose success.</code>
<span>但我可以选择成功。</span>
<code>I am in charge. My opinion matters.</code>
<span>我负责。我的意见就很重要。</span>
<code>That's the first rule of algorithms.</code>
<span>这就是算法的第一个规则。</span>
<code>Algorithms are opinions embedded in code.</code>
<span>算法是嵌入在代码中的观点。</span>
<code>It's really different from what you think most people think of algorithms.</code>
<span>这和你认为大多数人对 算法的看法是不同的。</span>
<code>They think algorithms are objective and true and scientific.</code>
<span>他们认为算法是客观、真实和科学的。</span>
<code>That's a marketing trick.</code>
<span>那是一种营销技巧。</span>
<code>It's also a marketing trick</code>
<span>这也是一种用算法来</span>
<code>to intimidate you with algorithms,</code>
<span>恐吓你的营销手段，</span>
<code>to make you trust and fear algorithms</code>
<span>为了让你信任和恐惧算法</span>
<code>because you trust and fear mathematics.</code>
<span>因为你信任并害怕数学。</span>
<code>A lot can go wrong when we put blind faith in big data.</code>
<span>当我们盲目信任大数据时， 很多人都可能犯错。</span>
<code>This is Kiri Soares. She's a high school principal in Brooklyn.</code>
<span>这是凯丽·索尔斯。 她是布鲁克林的一名高中校长。</span>
<code>In 2011, she told me her teachers were being scored</code>
<span>2011年，她告诉我， 她学校的老师们正在被一个复杂</span>
<code>with a complex, secret algorithm</code>
<span>并且隐秘的算法进行打分，</span>
<code>called the "value-added model."</code>
<span>这个算法被称为“增值模型"。</span>
<code>I told her, "Well, figure out what the formula is, show it to me.</code>
<span>我告诉她，“先弄清楚这个 公式是什么，然后给我看看。</span>
<code>I'm going to explain it to you."</code>
<span>我来给你解释一下。”</span>
<code>She said, "Well, I tried to get the formula,</code>
<span>她说，“我寻求过这个公式，</span>
<code>but my Department of Education contact told me it was math</code>
<span>但是教育部的负责人告诉我这是数学，</span>
<code>and I wouldn't understand it."</code>
<span>给我我也看不懂。”</span>
<code>It gets worse.</code>
<span>更糟的还在后面。</span>
<code>The New York Post filed a Freedom of Information Act request,</code>
<span>纽约邮报提出了“信息自由法”的要求，</span>
<code>got all the teachers' names and all their scores</code>
<span>来得到所有老师的名字与他们的分数，</span>
<code>and they published them as an act of teacher-shaming.</code>
<span>并且他们以羞辱教师的方式 发表了这些数据。</span>
<code>When I tried to get the formulas, the source code, through the same means,</code>
<span>当我试图用同样的方法来获取公式， 源代码的时候，</span>
<code>I was told I couldn't.</code>
<span>我被告知我没有权力这么做。</span>
<code>I was denied.</code>
<span>我被拒绝了。</span>
<code>I later found out</code>
<span>后来我发现，</span>
<code>that nobody in New York City had access to that formula.</code>
<span>纽约市压根儿没有人能接触到这个公式。</span>
<code>No one understood it.</code>
<span>没有人能看懂。</span>
<code>Then someone really smart got involved, Gary Rubinstein.</code>
<span>然后，一个非常聪明的人参与了， 加里·鲁宾斯坦。</span>
<code>He found 665 teachers from that New York Post data</code>
<span>他从纽约邮报的数据中 找到了665名教师，</span>
<code>that actually had two scores.</code>
<span>实际上他们有两个分数。</span>
<code>That could happen if they were teaching</code>
<span>如果他们同时教七年级与八年级的数学，</span>
<code>seventh grade math and eighth grade math.</code>
<span>就会得到两个评分。</span>
<code>He decided to plot them.</code>
<span>他决定把这些数据绘成图表。</span>
<code>Each dot represents a teacher.</code>
<span>每个点代表一个教师。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>What is that?</code>
<span>那是什么？</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>That should never have been used for individual assessment.</code>
<span>它永远不应该被用于个人评估。</span>
<code>It's almost a random number generator.</code>
<span>它几乎是一个随机数生成器。</span>
<code>(Applause)</code>
<span>（掌声）</span>
<code>But it was.</code>
<span>但它确实被使用了。</span>
<code>This is Sarah Wysocki.</code>
<span>这是莎拉·维索斯基。</span>
<code>She got fired, along with 205 other teachers,</code>
<span>她连同另外205名教师被解雇了，</span>
<code>from the Washington, DC school district,</code>
<span>都是来自华盛顿特区的学区，</span>
<code>even though she had great recommendations from her principal</code>
<span>尽管她的校长还有学生的</span>
<code>and the parents of her kids.</code>
<span>父母都非常推荐她。</span>
<code>I know what a lot of you guys are thinking,</code>
<span>我知道你们很多人在想什么，</span>
<code>especially the data scientists, the AI experts here.</code>
<span>尤其是这里的数据科学家， 人工智能专家。</span>
<code>You're thinking, "Well, I would never make an algorithm that inconsistent."</code>
<span>你在想，“我可永远不会做出 这样前后矛盾的算法。”</span>
<code>But algorithms can go wrong,</code>
<span>但是算法可能会出错，</span>
<code>even have deeply destructive effects with good intentions.</code>
<span>即使有良好的意图， 也会产生毁灭性的影响。</span>
<code>And whereas an airplane that's designed badly</code>
<span>每个人都能看到一架设计的</span>
<code>crashes to the earth and everyone sees it,</code>
<span>很糟糕的飞机会坠毁在地，</span>
<code>an algorithm designed badly</code>
<span>而一个设计糟糕的算法</span>
<code>can go on for a long time, silently wreaking havoc.</code>
<span>可以持续很长一段时间， 并无声地造成破坏。</span>
<code>This is Roger Ailes.</code>
<span>这是罗杰·艾尔斯。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>He founded Fox News in 1996.</code>
<span>他在1996年创办了福克斯新闻。</span>
<code>More than 20 women complained about sexual harassment.</code>
<span>公司有超过20多名女性曾抱怨过性骚扰。</span>
<code>They said they weren't allowed to succeed at Fox News.</code>
<span>她们说她们不被允许在 福克斯新闻有所成就。</span>
<code>He was ousted last year, but we've seen recently</code>
<span>他去年被赶下台，但我们最近看到</span>
<code>that the problems have persisted.</code>
<span>问题依然存在。</span>
<code>That begs the question:</code>
<span>这引出了一个问题：</span>
<code>What should Fox News do to turn over another leaf?</code>
<span>福克斯新闻应该做些什么改变？</span>
<code>Well, what if they replaced their hiring process</code>
<span>如果他们用机器学习算法</span>
<code>with a machine-learning algorithm?</code>
<span>取代传统的招聘流程呢？</span>
<code>That sounds good, right?</code>
<span>听起来不错，对吧？</span>
<code>Think about it.</code>
<span>想想看。</span>
<code>The data, what would the data be?</code>
<span>数据，这些数据到底是什么？</span>
<code>A reasonable choice would be the last 21 years of applications to Fox News.</code>
<span>福克斯新闻在过去21年的申请函 是一个合理的选择。</span>
<code>Reasonable.</code>
<span>很合理。</span>
<code>What about the definition of success?</code>
<span>那么成功的定义呢？</span>
<code>Reasonable choice would be,</code>
<span>合理的选择将是，</span>
<code>well, who is successful at Fox News?</code>
<span>谁在福克斯新闻取得了成功？</span>
<code>I guess someone who, say, stayed there for four years</code>
<span>我猜的是，比如在那里呆了四年，</span>
<code>and was promoted at least once.</code>
<span>至少得到过一次晋升的人。</span>
<code>Sounds reasonable.</code>
<span>听起来很合理。</span>
<code>And then the algorithm would be trained.</code>
<span>然后这个算法将会被训练。</span>
<code>It would be trained to look for people to learn what led to success,</code>
<span>它会被训练去向人们 学习是什么造就了成功，</span>
<code>what kind of applications historically led to success</code>
<span>什么样的申请函在过去拥有</span>
<code>by that definition.</code>
<span>这种成功的定义。</span>
<code>Now think about what would happen</code>
<span>现在想想如果我们把它</span>
<code>if we applied that to a current pool of applicants.</code>
<span>应用到目前的申请者中会发生什么。</span>
<code>It would filter out women</code>
<span>它会过滤掉女性，</span>
<code>because they do not look like people who were successful in the past.</code>
<span>因为她们看起来不像 在过去取得成功的人。</span>
<code>Algorithms don't make things fair</code>
<span>算法不会让事情变得公平，</span>
<code>if you just blithely, blindly apply algorithms.</code>
<span>如果你只是轻率地， 盲目地应用算法。</span>
<code>They don't make things fair.</code>
<span>它们不会让事情变得公平。</span>
<code>They repeat our past practices,</code>
<span>它们只是重复我们过去的做法，</span>
<code>our patterns.</code>
<span>我们的规律。</span>
<code>They automate the status quo.</code>
<span>它们使现状自动化。</span>
<code>That would be great if we had a perfect world,</code>
<span>如果我们有一个 完美的世界那就太好了，</span>
<code>but we don't.</code>
<span>但是我们没有。</span>
<code>And I'll add that most companies don't have embarrassing lawsuits,</code>
<span>我还要补充一点， 大多数公司都没有令人尴尬的诉讼，</span>
<code>but the data scientists in those companies</code>
<span>但是这些公司的数据科学家</span>
<code>are told to follow the data,</code>
<span>被告知要跟随数据，</span>
<code>to focus on accuracy.</code>
<span>关注它的准确性。</span>
<code>Think about what that means.</code>
<span>想想这意味着什么。</span>
<code>Because we all have bias, it means they could be codifying sexism</code>
<span>因为我们都有偏见， 这意味着他们可以编纂性别歧视</span>
<code>or any other kind of bigotry.</code>
<span>或者任何其他的偏见。</span>
<code>Thought experiment,</code>
<span>思维实验，</span>
<code>because I like them:</code>
<span>因为我喜欢它们：</span>
<code>an entirely segregated society --</code>
<span>一个完全隔离的社会——</span>
<code>racially segregated, all towns, all neighborhoods</code>
<span>种族隔离存在于所有的城镇， 所有的社区，</span>
<code>and where we send the police only to the minority neighborhoods</code>
<span>我们把警察只送到少数族裔的社区</span>
<code>to look for crime.</code>
<span>去寻找犯罪。</span>
<code>The arrest data would be very biased.</code>
<span>逮捕数据将会是十分有偏见的。</span>
<code>What if, on top of that, we found the data scientists</code>
<span>除此之外，我们还会寻找数据科学家</span>
<code>and paid the data scientists to predict where the next crime would occur?</code>
<span>并付钱给他们来预测 下一起犯罪会发生在哪里？</span>
<code>Minority neighborhood.</code>
<span>少数族裔的社区。</span>
<code>Or to predict who the next criminal would be?</code>
<span>或者预测下一个罪犯会是谁？</span>
<code>A minority.</code>
<span>少数族裔。</span>
<code>The data scientists would brag about how great and how accurate</code>
<span>这些数据科学家们 会吹嘘他们的模型有多好，</span>
<code>their model would be,</code>
<span>多精确，</span>
<code>and they'd be right.</code>
<span>当然他们是对的。</span>
<code>Now, reality isn't that drastic, but we do have severe segregations</code>
<span>不过现实并没有那么极端， 但我们确实在许多城市里</span>
<code>in many cities and towns,</code>
<span>有严重的种族隔离，</span>
<code>and we have plenty of evidence</code>
<span>并且我们有大量的证据表明</span>
<code>of biased policing and justice system data.</code>
<span>警察和司法系统的数据存有偏见。</span>
<code>And we actually do predict hotspots,</code>
<span>而且我们确实预测过热点，</span>
<code>places where crimes will occur.</code>
<span>那些犯罪会发生的地方。</span>
<code>And we do predict, in fact, the individual criminality,</code>
<span>我们确实会预测个人犯罪，</span>
<code>the criminality of individuals.</code>
<span>个人的犯罪行为。</span>
<code>The news organization ProPublica recently looked into</code>
<span>新闻机构“人民 (ProPublica)”最近调查了，</span>
<code>one of those "recidivism risk" algorithms,</code>
<span>其中一个称为</span>
<code>as they're called,</code>
<span>“累犯风险”的算法。</span>
<code>being used in Florida during sentencing by judges.</code>
<span>并在佛罗里达州的 宣判期间被法官采用。</span>
<code>Bernard, on the left, the black man, was scored a 10 out of 10.</code>
<span>伯纳德，左边的那个黑人， 10分中得了满分。</span>
<code>Dylan, on the right, 3 out of 10.</code>
<span>在右边的迪伦， 10分中得了3分。</span>
<code>10 out of 10, high risk. 3 out of 10, low risk.</code>
<span>10分代表高风险。 3分代表低风险。</span>
<code>They were both brought in for drug possession.</code>
<span>他们都因为持有毒品 而被带进了监狱。</span>
<code>They both had records,</code>
<span>他们都有犯罪记录，</span>
<code>but Dylan had a felony</code>
<span>但是迪伦有一个重罪</span>
<code>but Bernard didn't.</code>
<span>但伯纳德没有。</span>
<code>This matters, because the higher score you are,</code>
<span>这很重要，因为你的分数越高，</span>
<code>the more likely you're being given a longer sentence.</code>
<span>你被判长期服刑的可能性就越大。</span>
<code>What's going on?</code>
<span>到底发生了什么？</span>
<code>Data laundering.</code>
<span>数据洗钱。</span>
<code>It's a process by which technologists hide ugly truths</code>
<span>这是一个技术人员 把丑陋真相隐藏在</span>
<code>inside black box algorithms</code>
<span>算法黑盒子中的过程，</span>
<code>and call them objective;</code>
<span>并称之为客观；</span>
<code>call them meritocratic.</code>
<span>称之为精英模式。</span>
<code>When they're secret, important and destructive,</code>
<span>当它们是秘密的， 重要的并具有破坏性的，</span>
<code>I've coined a term for these algorithms:</code>
<span>我为这些算法创造了一个术语：</span>
<code>"weapons of math destruction."</code>
<span>“杀伤性数学武器”。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>(Applause)</code>
<span>（鼓掌）</span>
<code>They're everywhere, and it's not a mistake.</code>
<span>它们无处不在，也不是一个错误。</span>
<code>These are private companies building private algorithms</code>
<span>这些是私有公司为了私人目的</span>
<code>for private ends.</code>
<span>建立的私有算法。</span>
<code>Even the ones I talked about for teachers and the public police,</code>
<span>甚至是我谈到的老师 与公共警察使用的（算法），</span>
<code>those were built by private companies</code>
<span>也都是由私人公司所打造的，</span>
<code>and sold to the government institutions.</code>
<span>然后卖给政府机构。</span>
<code>They call it their "secret sauce" --</code>
<span>他们称之为“秘密配方（来源）”——</span>
<code>that's why they can't tell us about it.</code>
<span>这就是他们不能告诉我们的原因。</span>
<code>It's also private power.</code>
<span>这也是私人权力。</span>
<code>They are profiting for wielding the authority of the inscrutable.</code>
<span>他们利用神秘莫测的权威来获利。</span>
<code>Now you might think, since all this stuff is private</code>
<span>你可能会想，既然所有这些都是私有的</span>
<code>and there's competition,</code>
<span>而且会有竞争，</span>
<code>maybe the free market will solve this problem.</code>
<span>也许自由市场会解决这个问题。</span>
<code>It won't.</code>
<span>然而并不会。</span>
<code>There's a lot of money to be made in unfairness.</code>
<span>在不公平的情况下， 有很多钱可以赚。</span>
<code>Also, we're not economic rational agents.</code>
<span>而且，我们不是经济理性的代理人。</span>
<code>We all are biased.</code>
<span>我们都是有偏见的。</span>
<code>We're all racist and bigoted in ways that we wish we weren't,</code>
<span>我们都是固执的种族主义者， 虽然我们希望我们不是，</span>
<code>in ways that we don't even know.</code>
<span>虽然我们甚至没有意识到。</span>
<code>We know this, though, in aggregate,</code>
<span>总的来说，我们知道这一点，</span>
<code>because sociologists have consistently demonstrated this</code>
<span>因为社会学家会一直通过这些实验</span>
<code>with these experiments they build,</code>
<span>来证明这一点，</span>
<code>where they send a bunch of applications to jobs out,</code>
<span>他们发送了大量的工作申请，</span>
<code>equally qualified but some have white-sounding names</code>
<span>都是有同样资格的候选人， 有些用白人人名，</span>
<code>and some have black-sounding names,</code>
<span>有些用黑人人名，</span>
<code>and it's always disappointing, the results -- always.</code>
<span>然而结果总是令人失望的。</span>
<code>So we are the ones that are biased,</code>
<span>所以我们是有偏见的，</span>
<code>and we are injecting those biases into the algorithms</code>
<span>我们还通过选择收集到的数据</span>
<code>by choosing what data to collect,</code>
<span>来把偏见注入到算法中，</span>
<code>like I chose not to think about ramen noodles --</code>
<span>就像我不选择去想拉面一样——</span>
<code>I decided it was irrelevant.</code>
<span>我自认为这无关紧要。</span>
<code>But by trusting the data that's actually picking up on past practices</code>
<span>但是，通过信任那些 在过去的实践中获得的数据</span>
<code>and by choosing the definition of success,</code>
<span>以及通过选择成功的定义，</span>
<code>how can we expect the algorithms to emerge unscathed?</code>
<span>我们怎么能指望算法 会是毫无瑕疵的呢？</span>
<code>We can't. We have to check them.</code>
<span>我们不能。我们必须检查。</span>
<code>We have to check them for fairness.</code>
<span>我们必须检查它们是否公平。</span>
<code>The good news is, we can check them for fairness.</code>
<span>好消息是，我们可以做到这一点。</span>
<code>Algorithms can be interrogated,</code>
<span>算法是可以被审问的，</span>
<code>and they will tell us the truth every time.</code>
<span>而且每次都能告诉我们真相。</span>
<code>And we can fix them. We can make them better.</code>
<span>然后我们可以修复它们。 我们可以让他们变得更好。</span>
<code>I call this an algorithmic audit,</code>
<span>我把它叫做算法审计，</span>
<code>and I'll walk you through it.</code>
<span>接下来我会为你们解释。</span>
<code>First, data integrity check.</code>
<span>首先，数据的完整性检查。</span>
<code>For the recidivism risk algorithm I talked about,</code>
<span>对于刚才提到过的累犯风险算法，</span>
<code>a data integrity check would mean we'd have to come to terms with the fact</code>
<span>数据的完整性检查将意味着 我们不得不接受这个事实，</span>
<code>that in the US, whites and blacks smoke pot at the same rate</code>
<span>在美国，白人和黑人 吸毒的比例是一样的，</span>
<code>but blacks are far more likely to be arrested --</code>
<span>但是黑人更有可能被逮捕——</span>
<code>four or five times more likely, depending on the area.</code>
<span>取决于区域，可能性是白人的4到5倍。</span>
<code>What is that bias looking like in other crime categories,</code>
<span>这种偏见在其他犯罪类别中 是什么样子的，</span>
<code>and how do we account for it?</code>
<span>我们又该如何解释呢？</span>
<code>Second, we should think about the definition of success,</code>
<span>其次，我们应该考虑成功的定义，</span>
<code>audit that.</code>
<span>审计它。</span>
<code>Remember -- with the hiring algorithm? We talked about it.</code>
<span>还记得我们谈论的雇佣算法吗？</span>
<code>Someone who stays for four years and is promoted once?</code>
<span>那个呆了四年的人， 然后被提升了一次？</span>
<code>Well, that is a successful employee,</code>
<span>这的确是一个成功的员工，</span>
<code>but it's also an employee that is supported by their culture.</code>
<span>但这也是一名受到公司文化支持的员工。</span>
<code>That said, also it can be quite biased.</code>
<span>也就是说， 这可能会有很大的偏差。</span>
<code>We need to separate those two things.</code>
<span>我们需要把这两件事分开。</span>
<code>We should look to the blind orchestra audition</code>
<span>我们应该去看一下乐团盲选试奏，</span>
<code>as an example.</code>
<span>举个例子。</span>
<code>That's where the people auditioning are behind a sheet.</code>
<span>这就是人们在幕后选拔乐手的地方。</span>
<code>What I want to think about there</code>
<span>我想要考虑的是</span>
<code>is the people who are listening have decided what's important</code>
<span>倾听的人已经 决定了什么是重要的，</span>
<code>and they've decided what's not important,</code>
<span>同时他们已经决定了 什么是不重要的，</span>
<code>and they're not getting distracted by that.</code>
<span>他们也不会因此而分心。</span>
<code>When the blind orchestra auditions started,</code>
<span>当乐团盲选开始时，</span>
<code>the number of women in orchestras went up by a factor of five.</code>
<span>在管弦乐队中， 女性的数量上升了5倍。</span>
<code>Next, we have to consider accuracy.</code>
<span>其次，我们必须考虑准确性。</span>
<code>This is where the value-added model for teachers would fail immediately.</code>
<span>这就是针对教师的增值模型 立刻失效的地方。</span>
<code>No algorithm is perfect, of course,</code>
<span>当然，没有一个算法是完美的，</span>
<code>so we have to consider the errors of every algorithm.</code>
<span>所以我们要考虑每一个算法的误差。</span>
<code>How often are there errors, and for whom does this model fail?</code>
<span>出现错误的频率有多高， 让这个模型失败的对象是谁？</span>
<code>What is the cost of that failure?</code>
<span>失败的代价是什么？</span>
<code>And finally, we have to consider</code>
<span>最后，我们必须考虑</span>
<code>the long-term effects of algorithms,</code>
<span>这个算法的长期效果，</span>
<code>the feedback loops that are engendering.</code>
<span>与正在产生的反馈循环。</span>
<code>That sounds abstract,</code>
<span>这听起来很抽象，</span>
<code>but imagine if Facebook engineers had considered that</code>
<span>但是想象一下 如果脸书的工程师们之前考虑过，</span>
<code>before they decided to show us only things that our friends had posted.</code>
<span>并决定只向我们展示 我们朋友所发布的东西。</span>
<code>I have two more messages, one for the data scientists out there.</code>
<span>我还有两条建议， 一条是给数据科学家的。</span>
<code>Data scientists: we should not be the arbiters of truth.</code>
<span>数据科学家们：我们不应该 成为真相的仲裁者。</span>
<code>We should be translators of ethical discussions that happen</code>
<span>我们应该成为大社会中 所发生的道德讨论的</span>
<code>in larger society.</code>
<span>翻译者。</span>
<code>(Applause)</code>
<span>（掌声）</span>
<code>And the rest of you,</code>
<span>然后剩下的人，</span>
<code>the non-data scientists:</code>
<span>非数据科学家们：</span>
<code>this is not a math test.</code>
<span>这不是一个数学测试。</span>
<code>This is a political fight.</code>
<span>这是一场政治斗争。</span>
<code>We need to demand accountability for our algorithmic overlords.</code>
<span>我们应该要求我们的 算法霸主承担问责。</span>
<code>(Applause)</code>
<span>（掌声）</span>
<code>The era of blind faith in big data must end.</code>
<span>盲目信仰大数据的时代必须结束。</span>
<code>Thank you very much.</code>
<span>非常感谢。</span>
<code>(Applause)</code>
<span>（掌声）</span></p><center><a style="color: rgb(254,17,130)" href="https://icp.gov.moe/?keyword=20223985" target="_blank">萌ICP备20223985号</a></center></div></div>
</body>
</html>