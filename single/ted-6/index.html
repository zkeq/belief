<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<link rel="shortcut icon" href="/favicon.ico">
<meta name="referrer" content="no-referrer">
<script src="/yinghua/Ascii.js"></script>
<script src="/dplayer/dplayer.js"></script>
<link rel="stylesheet" href="/css/daily.css">

<title>【TED】如何赋予AI力量而不是被它压倒</title>
</head>
<body class='dream-plan os-windows'><div class='dream-plan-content'>
<div id='write'  class=''><blockquote><p><span>声明: 本站全部内容源自互联网,不进行任何盈利行为</span></p><p><strong><span>仅做 整合 / 美化 处理</span></strong></p><p><span>首页: </span><a href='https://dream-plan.cn' target='_blank' class='url'>https://dream-plan.cn</a><span> </span></p></blockquote><h2 id='title'><span>【TED】如何赋予AI力量而不是被它压倒</span></h2><div id="play"></div>
<script>
const play = new DPlayer({
    container: document.getElementById('play'),
    theme:'#c61e07',
    preload:'none',
    video: {
        pic:'https://cdn.read.html5.qq.com/image?src=circle&q=0&r=0&imgflag=0&cdn_cache=1800&w=0&h=0&imageUrl=https://s-bj-2220-zkeq.oss.dogecdn.com/head.jpg',
        url: 'https://mov.bn.netease.com/open-movie/nos/mp4/2022/01/17/SGT0CTEFV_shd.mp4'
    },
    subtitle: {
        url:'https://s-bj-2220-open-srt.oss.dogecdn.com/6.vtt',
        fontSize: '25px',
    },
});
</script><p>&nbsp;</p><p><code>After 13.8 billion years of cosmic history,</code>
<span>在 138 亿年的历史之后，</span>
<code>our universe has woken up</code>
<span>我们的宇宙终于觉醒了，</span>
<code>and become aware of itself.</code>
<span>并开始有了自我意识。</span>
<code>From a small blue planet,</code>
<span>从一颗蓝色的小星球，</span>
<code>tiny, conscious parts of our universe have begun gazing out into the cosmos</code>
<span>宇宙中那些有了微小意识的部分， 开始用它们的望远镜，</span>
<code>with telescopes,</code>
<span>窥视整个宇宙，</span>
<code>discovering something humbling.</code>
<span>从而有了谦卑的发现。</span>
<code>We've discovered that our universe is vastly grander</code>
<span>宇宙比我们祖先所想象的</span>
<code>than our ancestors imagined</code>
<span>要大得多，</span>
<code>and that life seems to be an almost imperceptibly small perturbation</code>
<span>使得生命显得如同渺小的扰动， 小到足以被忽视，</span>
<code>on an otherwise dead universe.</code>
<span>但若没有它们的存在， 宇宙也没了生命。</span>
<code>But we've also discovered something inspiring,</code>
<span>不过我们也发现了 一些振奋人心的事，</span>
<code>which is that the technology we're developing has the potential</code>
<span>那就是我们所开发的技术， 有着前所未有的潜能</span>
<code>to help life flourish like never before,</code>
<span>去促使生命变得更加繁盛，</span>
<code>not just for centuries but for billions of years,</code>
<span>不仅仅只有几个世纪， 而是持续了数十亿年；</span>
<code>and not just on earth but throughout much of this amazing cosmos.</code>
<span>也不仅仅是地球上， 甚至是在整个浩瀚的宇宙中。</span>
<code>I think of the earliest life as "Life 1.0"</code>
<span>我把最早的生命 称之为 “生命 1.0”，</span>
<code>because it was really dumb,</code>
<span>因为它那会儿还略显蠢笨，</span>
<code>like bacteria, unable to learn anything during its lifetime.</code>
<span>就像细菌，在它们的一生中， 也不会学到什么东西。</span>
<code>I think of us humans as "Life 2.0" because we can learn,</code>
<span>我把我们人类称为 “生命 2.0”， 因为我们能够学习，</span>
<code>which we in nerdy, geek speak,</code>
<span>用技术宅男的话来说，</span>
<code>might think of as installing new software into our brains,</code>
<span>就像是在我们脑袋里 装了一个新的软件，</span>
<code>like languages and job skills.</code>
<span>比如语言及工作技能。</span>
<code>"Life 3.0," which can design not only its software but also its hardware</code>
<span>而“生命 3.0” 不仅能开始设计 它的软件，甚至还可以创造其硬件。</span>
<code>of course doesn't exist yet.</code>
<span>当然，它目前还不存在。</span>
<code>But perhaps our technology has already made us "Life 2.1,"</code>
<span>但是也许我们的科技 已经让我们走进了 “生命 2.1”，</span>
<code>with our artificial knees, pacemakers and cochlear implants.</code>
<span>因为现在我们有了人工膝盖， 心脏起搏器以及耳蜗植入技术。</span>
<code>So let's take a closer look at our relationship with technology, OK?</code>
<span>我们一起来聊聊 人类和科技的关系吧！</span>
<code>As an example,</code>
<span>举个例子，</span>
<code>the Apollo 11 moon mission was both successful and inspiring,</code>
<span>阿波罗 11 号月球任务 很成功，令人备受鼓舞，</span>
<code>showing that when we humans use technology wisely,</code>
<span>展示出了我们人类 对于使用科技的智慧，</span>
<code>we can accomplish things that our ancestors could only dream of.</code>
<span>我们实现了很多 祖先们只能想象的事情。</span>
<code>But there's an even more inspiring journey</code>
<span>但还有一段更加 鼓舞人心的旅程，</span>
<code>propelled by something more powerful than rocket engines,</code>
<span>由比火箭引擎更加强大的 东西所推动着，</span>
<code>where the passengers aren't just three astronauts</code>
<span>乘客也不仅仅只是三个宇航员，</span>
<code>but all of humanity.</code>
<span>而是我们全人类。</span>
<code>Let's talk about our collective journey into the future</code>
<span>让我们来聊聊与人工智能 一起走向未来的</span>
<code>with artificial intelligence.</code>
<span>这段旅程。</span>
<code>My friend Jaan Tallinn likes to point out that just as with rocketry,</code>
<span>我的朋友扬·塔林（Jaan Tallinn）常说， 这就像是火箭学一样，</span>
<code>it's not enough to make our technology powerful.</code>
<span>只让我们的科技 拥有强大的力量是不够的。</span>
<code>We also have to figure out, if we're going to be really ambitious,</code>
<span>如果我们有足够的 雄心壮志，就应当想出</span>
<code>how to steer it</code>
<span>如何控制它们的方法，</span>
<code>and where we want to go with it.</code>
<span>希望它朝着怎样的方向前进。</span>
<code>So let's talk about all three for artificial intelligence:</code>
<span>那么对于人工智能， 我们先来谈谈这三点：</span>
<code>the power, the steering and the destination.</code>
<span>力量，操控和目的地。</span>
<code>Let's start with the power.</code>
<span>我们先来说力量。</span>
<code>I define intelligence very inclusively --</code>
<span>我对于人工智能的定义非常全面——</span>
<code>simply as our ability to accomplish complex goals,</code>
<span>就是我们能够完成复杂目标的能力，</span>
<code>because I want to include both biological and artificial intelligence.</code>
<span>因为我想把生物学 和人工智能都包含进去。</span>
<code>And I want to avoid the silly carbon-chauvinism idea</code>
<span>我还想要避免愚蠢的 碳沙文主义的观点，</span>
<code>that you can only be smart if you're made of meat.</code>
<span>即你认为如果你很聪明， 你就一定有着肉身。</span>
<code>It's really amazing how the power of AI has grown recently.</code>
<span>人工智能的力量 在近期的发展十分惊人。</span>
<code>Just think about it.</code>
<span>试想一下。</span>
<code>Not long ago, robots couldn't walk.</code>
<span>甚至在不久以前， 机器人还不能走路呢。</span>
<code>Now, they can do backflips.</code>
<span>现在，它们居然开始后空翻了。</span>
<code>Not long ago,</code>
<span>不久以前，</span>
<code>we didn't have self-driving cars.</code>
<span>我们还没有全自动驾驶汽车。</span>
<code>Now, we have self-flying rockets.</code>
<span>现在，我们都有 自动飞行的火箭了。</span>
<code>Not long ago,</code>
<span>不久以前，</span>
<code>AI couldn't do face recognition.</code>
<span>人工智能甚至不能完成脸部识别。</span>
<code>Now, AI can generate fake faces</code>
<span>现在，人工智能都开始 生成仿真面貌了，</span>
<code>and simulate your face saying stuff that you never said.</code>
<span>并模拟你的脸部表情， 说出你从未说过的话。</span>
<code>Not long ago,</code>
<span>不久以前，</span>
<code>AI couldn't beat us at the game of Go.</code>
<span>人工智能还不能在围棋中战胜人类，</span>
<code>Then, Google DeepMind's AlphaZero AI took 3,000 years of human Go games</code>
<span>然后，谷歌的DeepMind推出的 AlphaZero 就掌握了人类三千多年的</span>
<code>and Go wisdom,</code>
<span>围棋比赛和智慧，</span>
<code>ignored it all and became the world's best player by just playing against itself.</code>
<span>通过和自己对战的方式轻松秒杀我们， 成了全球最厉害的围棋手。</span>
<code>And the most impressive feat here wasn't that it crushed human gamers,</code>
<span>这里最让人印象深刻的部分， 不是它击垮了人类棋手，</span>
<code>but that it crushed human AI researchers</code>
<span>而是它击垮了人类人工智能的研究者，</span>
<code>who had spent decades handcrafting game-playing software.</code>
<span>这些研究者花了数十年 手工打造了下棋软件。</span>
<code>And AlphaZero crushed human AI researchers not just in Go but even at chess,</code>
<span>此外，AlphaZero也在国际象棋比赛中 轻松战胜了人类的人工智能研究者们，</span>
<code>which we have been working on since 1950.</code>
<span>我们从 1950 年 就开始致力于国际象棋研究。</span>
<code>So all this amazing recent progress in AI really begs the question:</code>
<span>所以近来，这些惊人的 人工智能进步，让大家不禁想问：</span>
<code>How far will it go?</code>
<span>它到底能达到怎样的程度？</span>
<code>I like to think about this question</code>
<span>我在思考这个问题时，</span>
<code>in terms of this abstract landscape of tasks,</code>
<span>想从工作任务中的抽象地景来切入，</span>
<code>where the elevation represents how hard it is for AI to do each task</code>
<span>图中的海拔高度表示 人工智能要把每一项工作</span>
<code>at human level,</code>
<span>做到人类的水平的难度，</span>
<code>and the sea level represents what AI can do today.</code>
<span>海平面表示现今的 人工智能所达到的水平。</span>
<code>The sea level is rising as AI improves,</code>
<span>随着人工智能的进步， 海平面会上升，</span>
<code>so there's a kind of global warming going on here in the task landscape.</code>
<span>所以在这工作任务地景上， 有着类似全球变暖的后果。</span>
<code>And the obvious takeaway is to avoid careers at the waterfront --</code>
<span>很显然，我们要避免 从事那些近海区的工作——</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>which will soon be automated and disrupted.</code>
<span>这些工作不会一直由人来完成， 迟早要被自动化取代。</span>
<code>But there's a much bigger question as well.</code>
<span>然而同时，还存在一个很大的问题，</span>
<code>How high will the water end up rising?</code>
<span>水平面最后会升到多高？</span>
<code>Will it eventually rise to flood everything,</code>
<span>它最后是否会升高到淹没一切，</span>
<code>matching human intelligence at all tasks.</code>
<span>人工智能会不会 最终能胜任所有的工作？</span>
<code>This is the definition of artificial general intelligence --</code>
<span>这就成了通用人工智能 （Artificial general intelligence）——</span>
<code>AGI,</code>
<span>缩写是 AGI，</span>
<code>which has been the holy grail of AI research since its inception.</code>
<span>从一开始它就是 人工智能研究最终的圣杯。</span>
<code>By this definition, people who say,</code>
<span>根据这个定义，有人说，</span>
<code>"Ah, there will always be jobs that humans can do better than machines,"</code>
<span>“总是有些工作， 人类可以做得比机器好的。”</span>
<code>are simply saying that we'll never get AGI.</code>
<span>意思就是，我们永远不会有 AGI。</span>
<code>Sure, we might still choose to have some human jobs</code>
<span>当然，我们可以仍然 保留一些人类的工作，</span>
<code>or to give humans income and purpose with our jobs,</code>
<span>或者说，通过我们的工作 带给人类收入和生活目标，</span>
<code>but AGI will in any case transform life as we know it</code>
<span>但是不论如何， AGI  都会转变我们对生命的认知，</span>
<code>with humans no longer being the most intelligent.</code>
<span>人类或许不再是最有智慧的了。</span>
<code>Now, if the water level does reach AGI,</code>
<span>如果海平面真的 上升到 AGI 的高度，</span>
<code>then further AI progress will be driven mainly not by humans but by AI,</code>
<span>那么进一步的人工智能进展 将会由人工智能来引领，而非人类，</span>
<code>which means that there's a possibility</code>
<span>那就意味着有可能，</span>
<code>that further AI progress could be way faster</code>
<span>进一步提升人工智能水平 将会进行得非常迅速，</span>
<code>than the typical human research and development timescale of years,</code>
<span>甚至超越用年份来计算时间的 典型人类研究和发展，</span>
<code>raising the controversial possibility of an intelligence explosion</code>
<span>提高到一种极具争议性的可能性， 那就是智能爆炸，</span>
<code>where recursively self-improving AI</code>
<span>即能够不断做自我改进的人工智能</span>
<code>rapidly leaves human intelligence far behind,</code>
<span>很快就会遥遥领先人类，</span>
<code>creating what's known as superintelligence.</code>
<span>创造出所谓的超级人工智能。</span>
<code>Alright, reality check:</code>
<span>好了，回归现实：</span>
<code>Are we going to get AGI any time soon?</code>
<span>我们很快就会有 AGI 吗？</span>
<code>Some famous AI researchers, like Rodney Brooks,</code>
<span>一些著名的 AI 研究者， 如罗德尼 · 布鲁克斯 （Rodney Brooks),</span>
<code>think it won't happen for hundreds of years.</code>
<span>认为一百年内是没有可能的。</span>
<code>But others, like Google DeepMind founder Demis Hassabis,</code>
<span>但是其他人，如谷歌DeepMind公司的 创始人德米斯 · 哈萨比斯（Demis Hassabis）</span>
<code>are more optimistic</code>
<span>就比较乐观，</span>
<code>and are working to try to make it happen much sooner.</code>
<span>且努力想要它尽早实现。</span>
<code>And recent surveys have shown that most AI researchers</code>
<span>近期的调查显示， 大部分的人工智能研究者</span>
<code>actually share Demis's optimism,</code>
<span>其实都和德米斯一样持乐观态度，</span>
<code>expecting that we will get AGI within decades,</code>
<span>预期我们十年内就会有 AGI，</span>
<code>so within the lifetime of many of us,</code>
<span>所以我们中许多人 在有生之年就能看到，</span>
<code>which begs the question -- and then what?</code>
<span>这就让人不禁想问—— 那么接下来呢？</span>
<code>What do we want the role of humans to be</code>
<span>如果什么事情机器 都能做得比人好，</span>
<code>if machines can do everything better and cheaper than us?</code>
<span>成本也更低，那么人类 又该扮演怎样的角色？</span>
<code>The way I see it, we face a choice.</code>
<span>依我所见，我们面临一个选择。</span>
<code>One option is to be complacent.</code>
<span>选择之一是要自我满足。</span>
<code>We can say, "Oh, let's just build machines that can do everything we can do</code>
<span>我们可以说，“我们来建造机器， 让它来帮助我们做一切事情，</span>
<code>and not worry about the consequences.</code>
<span>不要担心后果，</span>
<code>Come on, if we build technology that makes all humans obsolete,</code>
<span>拜托，如果我们能打造出 让全人类都被淘汰的机器，</span>
<code>what could possibly go wrong?"</code>
<span>还有什么会出错吗？”</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>But I think that would be embarrassingly lame.</code>
<span>但我觉得那样真是差劲到悲哀。</span>
<code>I think we should be more ambitious -- in the spirit of TED.</code>
<span>我们认为我们应该更有野心—— 带着 TED 的精神。</span>
<code>Let's envision a truly inspiring high-tech future</code>
<span>让我们来想象一个 真正鼓舞人心的高科技未来，</span>
<code>and try to steer towards it.</code>
<span>并试着朝着它前进。</span>
<code>This brings us to the second part of our rocket metaphor: the steering.</code>
<span>这就把我们带到了火箭比喻的 第二部分：操控。</span>
<code>We're making AI more powerful,</code>
<span>我们让人工智能的力量更强大，</span>
<code>but how can we steer towards a future</code>
<span>但是我们要如何朝着 人工智能帮助人类未来更加繁盛，</span>
<code>where AI helps humanity flourish rather than flounder?</code>
<span>而非变得挣扎的目标不断前进呢？</span>
<code>To help with this,</code>
<span>为了协助实现它，</span>
<code>I cofounded the Future of Life Institute.</code>
<span>我联合创办了 “未来生命研究所” （Future of Life Institute）。</span>
<code>It's a small nonprofit promoting beneficial technology use,</code>
<span>它是个小型的非营利机构， 旨在促进有益的科技使用，</span>
<code>and our goal is simply for the future of life to exist</code>
<span>我们的目标很简单， 就是希望生命的未来能够存在，</span>
<code>and to be as inspiring as possible.</code>
<span>且越是鼓舞人心越好。</span>
<code>You know, I love technology.</code>
<span>你们知道的，我爱科技。</span>
<code>Technology is why today is better than the Stone Age.</code>
<span>现今之所以比石器时代更好， 就是因为科技。</span>
<code>And I'm optimistic that we can create a really inspiring high-tech future ...</code>
<span>我很乐观的认为我们能创造出 一个非常鼓舞人心的高科技未来……</span>
<code>if -- and this is a big if --</code>
<span>如果——这个 “如果” 很重要——</span>
<code>if we win the wisdom race --</code>
<span>如果我们能赢得这场 关于智慧的赛跑——</span>
<code>the race between the growing power of our technology</code>
<span>这场赛跑的两位竞争者 便是我们不断成长的科技力量</span>
<code>and the growing wisdom with which we manage it.</code>
<span>以及我们用来管理科技的 不断成长的智慧。</span>
<code>But this is going to require a change of strategy</code>
<span>但这也需要策略上的改变。</span>
<code>because our old strategy has been learning from mistakes.</code>
<span>因为我们以往的策略 往往都是从错误中学习的。</span>
<code>We invented fire,</code>
<span>我们发明了火，</span>
<code>screwed up a bunch of times --</code>
<span>因为搞砸了很多次——</span>
<code>invented the fire extinguisher.</code>
<span>我们发明出了灭火器。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>We invented the car, screwed up a bunch of times --</code>
<span>我们发明了汽车， 又一不小心搞砸了很多次——</span>
<code>invented the traffic light, the seat belt and the airbag,</code>
<span>发明了红绿灯，安全带 和安全气囊，</span>
<code>but with more powerful technology like nuclear weapons and AGI,</code>
<span>但对于更强大的科技， 像是核武器和 AGI，</span>
<code>learning from mistakes is a lousy strategy,</code>
<span>要去从错误中学习， 似乎是个比较糟糕的策略，</span>
<code>don't you think?</code>
<span>你们怎么看？</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>It's much better to be proactive rather than reactive;</code>
<span>事前的准备比事后的 补救要好得多；</span>
<code>plan ahead and get things right the first time</code>
<span>提早做计划，争取一次成功，</span>
<code>because that might be the only time we'll get.</code>
<span>因为有时我们或许 没有第二次机会。</span>
<code>But it is funny because sometimes people tell me,</code>
<span>但有趣的是， 有时候有人告诉我。</span>
<code>"Max, shhh, don't talk like that.</code>
<span>“麦克斯，嘘——别那样说话。</span>
<code>That's Luddite scaremongering."</code>
<span>那是勒德分子（注：持有反机械化， 反自动化观点的人）在制造恐慌。“</span>
<code>But it's not scaremongering.</code>
<span>但这并不是制造恐慌。</span>
<code>It's what we at MIT call safety engineering.</code>
<span>在麻省理工学院， 我们称之为安全工程。</span>
<code>Think about it:</code>
<span>想想看：</span>
<code>before NASA launched the Apollo 11 mission,</code>
<span>在美国航天局（NASA） 部署阿波罗 11 号任务之前，</span>
<code>they systematically thought through everything that could go wrong</code>
<span>他们全面地设想过 所有可能出错的状况，</span>
<code>when you put people on top of explosive fuel tanks</code>
<span>毕竟是要把人类放进 易燃易爆的太空舱里，</span>
<code>and launch them somewhere where no one could help them.</code>
<span>再将他们发射上 一个无人能助的境遇。</span>
<code>And there was a lot that could go wrong.</code>
<span>可能出错的情况非常多，</span>
<code>Was that scaremongering?</code>
<span>那是在制造恐慌吗？</span>
<code>No.</code>
<span>不是。</span>
<code>That's was precisely the safety engineering</code>
<span>那正是在做安全工程的工作，</span>
<code>that ensured the success of the mission,</code>
<span>以确保任务顺利进行，</span>
<code>and that is precisely the strategy I think we should take with AGI.</code>
<span>这正是我认为处理 AGI 时 应该采取的策略。</span>
<code>Think through what can go wrong to make sure it goes right.</code>
<span>想清楚什么可能出错， 然后避免它的发生。</span>
<code>So in this spirit, we've organized conferences,</code>
<span>基于这样的精神， 我们组织了几场大会，</span>
<code>bringing together leading AI researchers and other thinkers</code>
<span>邀请了世界顶尖的人工智能研究者 和其他有想法的专业人士，</span>
<code>to discuss how to grow this wisdom we need to keep AI beneficial.</code>
<span>来探讨如何发展这样的智慧， 从而确保人工智能对人类有益。</span>
<code>Our last conference was in Asilomar, California last year</code>
<span>我们最近的一次大会 去年在加州的阿西洛玛举行，</span>
<code>and produced this list of 23 principles</code>
<span>我们得出了 23 条原则，</span>
<code>which have since been signed by over 1,000 AI researchers</code>
<span>自此已经有超过 1000 位 人工智能研究者，以及核心企业的</span>
<code>and key industry leaders,</code>
<span>领导人参与签署。</span>
<code>and I want to tell you about three of these principles.</code>
<span>我想要和各位分享 其中的三项原则。</span>
<code>One is that we should avoid an arms race and lethal autonomous weapons.</code>
<span>第一，我们需要避免军备竞赛， 以及致命的自动化武器出现。</span>
<code>The idea here is that any science can be used for new ways of helping people</code>
<span>其中的想法是，任何科学都可以 用新的方式来帮助人们，</span>
<code>or new ways of harming people.</code>
<span>同样也可以以新的方式 对我们造成伤害。</span>
<code>For example, biology and chemistry are much more likely to be used</code>
<span>例如，生物和化学更可能被用来</span>
<code>for new medicines or new cures than for new ways of killing people,</code>
<span>制造新的医药用品， 而非带来新的杀人方法，</span>
<code>because biologists and chemists pushed hard --</code>
<span>因为生物学家和 化学家很努力——</span>
<code>and successfully --</code>
<span>也很成功地——在推动</span>
<code>for bans on biological and chemical weapons.</code>
<span>禁止生化武器的出现。</span>
<code>And in the same spirit,</code>
<span>基于同样的精神，</span>
<code>most AI researchers want to stigmatize and ban lethal autonomous weapons.</code>
<span>大部分的人工智能研究者也在 试图指责和禁止致命的自动化武器。</span>
<code>Another Asilomar AI principle</code>
<span>另一条阿西洛玛 人工智能会议的原则是，</span>
<code>is that we should mitigate AI-fueled income inequality.</code>
<span>我们应该要减轻 由人工智能引起的收入不平等。</span>
<code>I think that if we can grow the economic pie dramatically with AI</code>
<span>我认为，我们能够大幅度利用 人工智能发展出一块经济蛋糕，</span>
<code>and we still can't figure out how to divide this pie</code>
<span>但却没能相处如何来分配它</span>
<code>so that everyone is better off,</code>
<span>才能让所有人受益，</span>
<code>then shame on us.</code>
<span>那可太丢人了。</span>
<code>(Applause)</code>
<span>（掌声）</span>
<code>Alright, now raise your hand if your computer has ever crashed.</code>
<span>那么问一个问题，如果 你的电脑有死机过的，请举手。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>Wow, that's a lot of hands.</code>
<span>哇，好多人举手。</span>
<code>Well, then you'll appreciate this principle</code>
<span>那么你们就会感谢这条准则，</span>
<code>that we should invest much more in AI safety research,</code>
<span>我们应该要投入更多 以确保对人工智能安全性的研究，</span>
<code>because as we put AI in charge of even more decisions and infrastructure,</code>
<span>因为我们让人工智能在主导 更多决策以及基础设施时，</span>
<code>we need to figure out how to transform today's buggy and hackable computers</code>
<span>我们要了解如何将 会出现程序错误以及有漏洞的电脑，</span>
<code>into robust AI systems that we can really trust,</code>
<span>转化为可靠的人工智能，</span>
<code>because otherwise,</code>
<span>否则的话，</span>
<code>all this awesome new technology can malfunction and harm us,</code>
<span>这些了不起的新技术 就会出现故障，反而伤害到我们，</span>
<code>or get hacked and be turned against us.</code>
<span>或被黑入以后转而对抗我们。</span>
<code>And this AI safety work has to include work on AI value alignment,</code>
<span>这项人工智能安全性的工作 必须包含对人工智能价值观的校准，</span>
<code>because the real threat from AGI isn't malice,</code>
<span>因为 AGI 会带来的威胁 通常并非出于恶意——</span>
<code>like in silly Hollywood movies,</code>
<span>就像是愚蠢的 好莱坞电影中表现的那样，</span>
<code>but competence --</code>
<span>而是源于能力——</span>
<code>AGI accomplishing goals that just aren't aligned with ours.</code>
<span>AGI 想完成的目标 与我们的目标背道而驰。</span>
<code>For example, when we humans drove the West African black rhino extinct,</code>
<span>例如，当我们人类促使了 西非的黑犀牛灭绝时，</span>
<code>we didn't do it because we were a bunch of evil rhinoceros haters, did we?</code>
<span>并不是因为我们是邪恶 且痛恨犀牛的家伙，对吧？</span>
<code>We did it because we were smarter than them</code>
<span>我们能够做到 只是因为我们比它们聪明，</span>
<code>and our goals weren't aligned with theirs.</code>
<span>而我们的目标和它们的目标相违背。</span>
<code>But AGI is by definition smarter than us,</code>
<span>但是 AGI 在定义上就比我们聪明，</span>
<code>so to make sure that we don't put ourselves in the position of those rhinos</code>
<span>所以必须确保我们别让 自己落到了黑犀牛的境遇，</span>
<code>if we create AGI,</code>
<span>如果我们发明 AGI，</span>
<code>we need to figure out how to make machines understand our goals,</code>
<span>首先就要解决如何 让机器明白我们的目标，</span>
<code>adopt our goals and retain our goals.</code>
<span>选择采用我们的目标， 并一直跟随我们的目标。</span>
<code>And whose goals should these be, anyway?</code>
<span>不过，这些目标到底是谁的目标？</span>
<code>Which goals should they be?</code>
<span>这些目标到底是什么目标？</span>
<code>This brings us to the third part of our rocket metaphor: the destination.</code>
<span>这就引出了火箭比喻的 第三部分：目的地。</span>
<code>We're making AI more powerful,</code>
<span>我们要让人工智能的力量更强大，</span>
<code>trying to figure out how to steer it,</code>
<span>试图想办法来操控它，</span>
<code>but where do we want to go with it?</code>
<span>但我们到底想把它带去何方呢？</span>
<code>This is the elephant in the room that almost nobody talks about --</code>
<span>这就像是房间里的大象， 显而易见却无人问津——</span>
<code>not even here at TED --</code>
<span>甚至在 TED 也没人谈论——</span>
<code>because we're so fixated on short-term AI challenges.</code>
<span>因为我们都把目光 聚焦于短期的人工智能挑战。</span>
<code>Look, our species is trying to build AGI,</code>
<span>你们看，我们人类 正在试图建造 AGI，</span>
<code>motivated by curiosity and economics,</code>
<span>由我们的好奇心 以及经济需求所带动，</span>
<code>but what sort of future society are we hoping for if we succeed?</code>
<span>但如果我们能成功， 希望能创造出怎样的未来社会呢？</span>
<code>We did an opinion poll on this recently,</code>
<span>最近对于这一点， 我们做了一次观点投票，</span>
<code>and I was struck to see</code>
<span>结果很让我惊讶，</span>
<code>that most people actually want us to build superintelligence:</code>
<span>大部分的人其实希望 我们能打造出超级人工智能：</span>
<code>AI that's vastly smarter than us in all ways.</code>
<span>在各个方面都 比我们聪明的人工智能，</span>
<code>What there was the greatest agreement on was that we should be ambitious</code>
<span>大家甚至一致希望 我们应该更有野心，</span>
<code>and help life spread into the cosmos,</code>
<span>并协助生命在宇宙中的拓展，</span>
<code>but there was much less agreement about who or what should be in charge.</code>
<span>但对于应该由谁，或者什么来主导， 大家就各持己见了。</span>
<code>And I was actually quite amused</code>
<span>有件事我觉得非常奇妙，</span>
<code>to see that there's some some people who want it to be just machines.</code>
<span>就是我看到有些人居然表示 让机器主导就好了。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>And there was total disagreement about what the role of humans should be,</code>
<span>至于人类该扮演怎样的角色， 大家的意见简直就是大相径庭，</span>
<code>even at the most basic level,</code>
<span>即使在最基础的层面上也是，</span>
<code>so let's take a closer look at possible futures</code>
<span>那么让我们进一步 去看看这些可能的未来，</span>
<code>that we might choose to steer toward, alright?</code>
<span>我们可能去往目的地，怎么样？</span>
<code>So don't get me wrong here.</code>
<span>别误会我的意思，</span>
<code>I'm not talking about space travel,</code>
<span>我不是在谈论太空旅行，</span>
<code>merely about humanity's metaphorical journey into the future.</code>
<span>只是打个比方， 人类进入未来的这个旅程。</span>
<code>So one option that some of my AI colleagues like</code>
<span>我的一些研究人工智能的同事 很喜欢的一个选择就是</span>
<code>is to build superintelligence and keep it under human control,</code>
<span>打造人工智能， 并确保它被人类所控制，</span>
<code>like an enslaved god,</code>
<span>就像被奴役起来的神一样，</span>
<code>disconnected from the internet</code>
<span>网络连接被断开，</span>
<code>and used to create unimaginable technology and wealth</code>
<span>为它的操控者创造出无法想象的</span>
<code>for whoever controls it.</code>
<span>科技和财富。</span>
<code>But Lord Acton warned us</code>
<span>但是艾克顿勋爵（Lord Acton） 警告过我们，</span>
<code>that power corrupts, and absolute power corrupts absolutely,</code>
<span>权力会带来腐败， 绝对的权力终将带来绝对的腐败，</span>
<code>so you might worry that maybe we humans just aren't smart enough,</code>
<span>所以也许你会担心 我们人类就是还不够聪明，</span>
<code>or wise enough rather,</code>
<span>或者不够智慧，</span>
<code>to handle this much power.</code>
<span>无法妥善处理过多的权力。</span>
<code>Also, aside from any moral qualms you might have</code>
<span>还有，除了对于奴役带来的优越感，</span>
<code>about enslaving superior minds,</code>
<span>你可能还会产生道德上的忧虑，</span>
<code>you might worry that maybe the superintelligence could outsmart us,</code>
<span>你也许会担心人工智能 能够在智慧上超越我们，</span>
<code>break out and take over.</code>
<span>奋起反抗，并取得我们的控制权。</span>
<code>But I also have colleagues who are fine with AI taking over</code>
<span>但是我也有同事认为， 让人工智能来操控一切也无可厚非，</span>
<code>and even causing human extinction,</code>
<span>造成人类灭绝也无妨，</span>
<code>as long as we feel the the AIs are our worthy descendants,</code>
<span>只要我们觉得人工智能 配得上成为我们的后代，</span>
<code>like our children.</code>
<span>就像是我们的孩子。</span>
<code>But how would we know that the AIs have adopted our best values</code>
<span>但是我们如何才能知道 人工智能汲取了我们最好的价值观，</span>
<code>and aren't just unconscious zombies tricking us into anthropomorphizing them?</code>
<span>而不是只是一个无情的僵尸， 让我们误以为它们有人性？</span>
<code>Also, shouldn't those people who don't want human extinction</code>
<span>此外，那些绝对不想 看到人类灭绝的人，</span>
<code>have a say in the matter, too?</code>
<span>对此应该也有话要说吧？</span>
<code>Now, if you didn't like either of those two high-tech options,</code>
<span>如果这两个高科技的选择 都不是你所希望的，</span>
<code>it's important to remember that low-tech is suicide</code>
<span>请记得，从宇宙历史的角度来看，</span>
<code>from a cosmic perspective,</code>
<span>低级的科技如同自杀，</span>
<code>because if we don't go far beyond today's technology,</code>
<span>因为如果我们不能 远远超越今天的科技，</span>
<code>the question isn't whether humanity is going to go extinct,</code>
<span>问题就不再是人类是否会灭绝，</span>
<code>merely whether we're going to get taken out</code>
<span>而是让我们灭绝的会是下一次</span>
<code>by the next killer asteroid, supervolcano</code>
<span>巨型流星撞击地球， 还是超级火山爆发，</span>
<code>or some other problem that better technology could have solved.</code>
<span>亦或是一些其他本该可以 由更好的科技来解决的问题。</span>
<code>So, how about having our cake and eating it ...</code>
<span>所以，为什么不干脆 坐享其成……</span>
<code>with AGI that's not enslaved</code>
<span>使用非奴役的 AGI，</span>
<code>but treats us well because its values are aligned with ours?</code>
<span>因为价值观和我们一致， 愿意和我们并肩作战的 AGI？</span>
<code>This is the gist of what Eliezer Yudkowsky has called "friendly AI,"</code>
<span>尤多科斯基（Eliezer Yudkowsky) 所谓的 “友善的人工智能” 就是如此，</span>
<code>and if we can do this, it could be awesome.</code>
<span>若我们能做到这点，那简直太棒了。</span>
<code>It could not only eliminate negative experiences like disease, poverty,</code>
<span>它或许不会解决负面的影响， 如疾病，贫穷，</span>
<code>crime and other suffering,</code>
<span>犯罪或是其它，</span>
<code>but it could also give us the freedom to choose</code>
<span>但是它会给予我们自由，</span>
<code>from a fantastic new diversity of positive experiences --</code>
<span>让我们从那些正面的 境遇中去选择——</span>
<code>basically making us the masters of our own destiny.</code>
<span>让我们成为自己命运的主人。</span>
<code>So in summary,</code>
<span>总的来说，</span>
<code>our situation with technology is complicated,</code>
<span>在科技上，我们的现状很复杂，</span>
<code>but the big picture is rather simple.</code>
<span>但是若从大局来看，又很简单。</span>
<code>Most AI researchers expect AGI within decades,</code>
<span>多数人工智能的研究者认为  AGI 能在未来十年内实现，</span>
<code>and if we just bumble into this unprepared,</code>
<span>如果我们没有事先 准备好去面对它们，</span>
<code>it will probably be the biggest mistake in human history --</code>
<span>就可能成为人类历史上 最大的一个错误——</span>
<code>let's face it.</code>
<span>我们要面对现实。</span>
<code>It could enable brutal, global dictatorship</code>
<span>它可能导致残酷的 全球独裁主义变成现实，</span>
<code>with unprecedented inequality, surveillance and suffering,</code>
<span>造成前所未有的 不平等监控和苦难，</span>
<code>and maybe even human extinction.</code>
<span>或许甚至导致人类灭绝。</span>
<code>But if we steer carefully,</code>
<span>但是如果我们能小心操控，</span>
<code>we could end up in a fantastic future where everybody's better off:</code>
<span>我们可能会有个美好的未来， 人人都会受益的未来，</span>
<code>the poor are richer, the rich are richer,</code>
<span>穷人变得富有，富人变得更富有，</span>
<code>everybody is healthy and free to live out their dreams.</code>
<span>每个人都是健康的， 能自由地去实现他们的梦想。</span>
<code>Now, hang on.</code>
<span>不过先别急。</span>
<code>Do you folks want the future that's politically right or left?</code>
<span>你们希望未来的政治 是左派还是右派？</span>
<code>Do you want the pious society with strict moral rules,</code>
<span>你们想要一个有 严格道德准则的社会，</span>
<code>or do you an hedonistic free-for-all,</code>
<span>还是一个人人可参与的 享乐主义社会，</span>
<code>more like Burning Man 24/7?</code>
<span>更像是个无时无刻 不在运转的火人盛会？</span>
<code>Do you want beautiful beaches, forests and lakes,</code>
<span>你们想要美丽的海滩、森林和湖泊，</span>
<code>or would you prefer to rearrange some of those atoms with the computers,</code>
<span>还是偏好用电脑 重新排列组成新的原子，</span>
<code>enabling virtual experiences?</code>
<span>实现真正的虚拟现实？</span>
<code>With friendly AI, we could simply build all of these societies</code>
<span>有了友善的人工智能， 我们就能轻而易举地建立这些社会，</span>
<code>and give people the freedom to choose which one they want to live in</code>
<span>让大家有自由去选择 想要生活在怎样的社会里，</span>
<code>because we would no longer be limited by our intelligence,</code>
<span>因为我们不会再受到 自身智慧的限制，</span>
<code>merely by the laws of physics.</code>
<span>唯一的限制只有物理的定律。</span>
<code>So the resources and space for this would be astronomical --</code>
<span>所以资源和空间会取之不尽——</span>
<code>literally.</code>
<span>毫不夸张。</span>
<code>So here's our choice.</code>
<span>我们的选择如下：</span>
<code>We can either be complacent about our future,</code>
<span>我们可以对未来感到自满，</span>
<code>taking as an article of blind faith</code>
<span>带着盲目的信念，</span>
<code>that any new technology is guaranteed to be beneficial,</code>
<span>相信任何科技必定是有益的，</span>
<code>and just repeat that to ourselves as a mantra over and over and over again</code>
<span>并将这个想法当作 圣歌一般，不断默念，</span>
<code>as we drift like a rudderless ship towards our own obsolescence.</code>
<span>让我们像漫无目的船只， 驶向自我消亡的结局。</span>
<code>Or we can be ambitious --</code>
<span>或者，我们可以拥有雄心壮志——</span>
<code>thinking hard about how to steer our technology</code>
<span>努力去找到操控我们科技的方法，</span>
<code>and where we want to go with it</code>
<span>以及向往的目的地，</span>
<code>to create the age of amazement.</code>
<span>创造出真正令人惊奇的时代。</span>
<code>We're all here to celebrate the age of amazement,</code>
<span>我们相聚在这里， 赞颂这令人惊奇的时代，</span>
<code>and I feel that its essence should lie in becoming not overpowered</code>
<span>我觉得，它的精髓应当是， 让科技赋予我们力量，</span>
<code>but empowered by our technology.</code>
<span>而非反过来受控于它。</span>
<code>Thank you.</code>
<span>谢谢大家。</span>
<code>(Applause)</code>
<span>（掌声）</span></p><center><a style="color: rgb(254,17,130)" href="https://icp.gov.moe/?keyword=20223985" target="_blank">萌ICP备20223985号</a></center></div></div>
</body>
</html>