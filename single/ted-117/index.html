<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<link rel="shortcut icon" href="/favicon.ico">
<meta name="referrer" content="no-referrer">
<script src="/yinghua/Ascii.js"></script>
<script src="/dplayer/dplayer.js"></script>
<link rel="stylesheet" href="/css/daily.css">

<title>【TED】创建一个更安全的AI的准则</title>
</head>
<body class='typora-export os-windows'><div class='typora-export-content'>
<div id='write'  class=''><blockquote><p><span>声明: 本站全部内容源自互联网,不进行任何盈利行为</span></p><p><strong><span>仅做 整合 / 美化 处理</span></strong></p><p><span>首页: </span><a href='https://dream-plan.cn' target='_blank' class='url'>https://dream-plan.cn</a><span> </span></p></blockquote><h2 id='title'><span>【TED】创建一个更安全的AI的准则</span></h2><div id="play"></div>
<script>
const play = new DPlayer({
    container: document.getElementById('play'),
    theme:'#c61e07',
    preload:'none',
    video: {
        pic:'https://s-bj-2220-zkeq.oss.dogecdn.com/head.jpg',
        url: 'https://mov.bn.netease.com/open-movie/nos/mp4/2021/08/23/SGH60IJ2L_shd.mp4'
    },
    subtitle: {
        url:'https://s-bj-2220-open-srt.oss.dogecdn.com/117.vtt',
        fontSize: '25px',
    },
});
</script><p>&nbsp;</p><p><code>This is Lee Sedol.</code>
<span>这是李世石。</span>
<code>Lee Sedol is one of the world's greatest Go players,</code>
<span>李世石是全世界 最顶尖的围棋高手之一，</span>
<code>and he's having what my friends in Silicon Valley call</code>
<span>在这一刻，他所经历的 足以让我硅谷的朋友们</span>
<code>a "Holy Cow" moment --</code>
<span>喊一句”我的天啊“——</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>a moment where we realize</code>
<span>在这一刻，我们意识到</span>
<code>that AI is actually progressing a lot faster than we expected.</code>
<span>原来人工智能发展的进程 比我们预想的要快得多。</span>
<code>So humans have lost on the Go board. What about the real world?</code>
<span>人们在围棋棋盘上已经输了， 那在现实世界中又如何呢？</span>
<code>Well, the real world is much bigger,</code>
<span>当然了，现实世界要 比围棋棋盘要大得多，</span>
<code>much more complicated than the Go board.</code>
<span>复杂得多。</span>
<code>It's a lot less visible,</code>
<span>相比之下每一步也没那么明确，</span>
<code>but it's still a decision problem.</code>
<span>但现实世界仍然是一个选择性问题。</span>
<code>And if we think about some of the technologies</code>
<span>如果我们想想那一些在不久的未来，</span>
<code>that are coming down the pike ...</code>
<span>即将来临的新科技……</span>
<code>Noriko [Arai] mentioned that reading is not yet happening in machines,</code>
<span>Noriko提到机器还不能进行阅读，</span>
<code>at least with understanding.</code>
<span>至少达不到理解的程度，</span>
<code>But that will happen,</code>
<span>但这迟早会发生，</span>
<code>and when that happens,</code>
<span>而当它发生时，</span>
<code>very soon afterwards,</code>
<span>不久之后，</span>
<code>machines will have read everything that the human race has ever written.</code>
<span>机器就将读遍人类写下的所有东西。</span>
<code>And that will enable machines,</code>
<span>这将使机器除了拥有</span>
<code>along with the ability to look further ahead than humans can,</code>
<span>比人类看得更远的能力，</span>
<code>as we've already seen in Go,</code>
<span>就像我们在围棋中看到的那样，</span>
<code>if they also have access to more information,</code>
<span>如果机器能接触到比人类更多的信息，</span>
<code>they'll be able to make better decisions in the real world than we can.</code>
<span>则将能够在现实世界中 做出比人类更好的选择。</span>
<code>So is that a good thing?</code>
<span>那这是一件好事吗？</span>
<code>Well, I hope so.</code>
<span>我当然希望如此。</span>
<code>Our entire civilization, everything that we value,</code>
<span>人类的全部文明， 我们所珍视的一切，</span>
<code>is based on our intelligence.</code>
<span>都是基于我们的智慧之上。</span>
<code>And if we had access to a lot more intelligence,</code>
<span>如果我们能掌控更强大的智能，</span>
<code>then there's really no limit to what the human race can do.</code>
<span>那我们人类的 创造力 就真的没有极限了。</span>
<code>And I think this could be, as some people have described it,</code>
<span>我认为这可能就像很多人描述的那样</span>
<code>the biggest event in human history.</code>
<span>会成为人类历史上最重要的事件。</span>
<code>So why are people saying things like this,</code>
<span>那为什么有的人会说出以下的言论，</span>
<code>that AI might spell the end of the human race?</code>
<span>说人工智能将是人类的末日呢？</span>
<code>Is this a new thing?</code>
<span>这是一个新事物吗？</span>
<code>Is it just Elon Musk and Bill Gates and Stephen Hawking?</code>
<span>这只关乎伊隆马斯克、 比尔盖茨，和斯提芬霍金吗？</span>
<code>Actually, no. This idea has been around for a while.</code>
<span>其实不是的，人工智能 这个概念已经存在很长时间了。</span>
<code>Here's a quotation:</code>
<span>请看这段话：</span>
<code>"Even if we could keep the machines in a subservient position,</code>
<span>“即便我们能够将机器 维持在一个屈服于我们的地位，</span>
<code>for instance, by turning off the power at strategic moments" --</code>
<span>比如说，在战略性时刻将电源关闭。”——</span>
<code>and I'll come back to that "turning off the power" idea later on --</code>
<span>我等会儿再来讨论 ”关闭电源“这一话题，</span>
<code>"we should, as a species, feel greatly humbled."</code>
<span>”我们，作为一个物种， 仍然应该自感惭愧。“</span>
<code>So who said this? This is Alan Turing in 1951.</code>
<span>这段话是谁说的呢？ 是阿兰图灵，他在1951年说的。</span>
<code>Alan Turing, as you know, is the father of computer science</code>
<span>阿兰图灵，众所皆知， 是计算机科学之父。</span>
<code>and in many ways, the father of AI as well.</code>
<span>从很多意义上说， 他也是人工智能之父。</span>
<code>So if we think about this problem,</code>
<span>当我们考虑这个问题，</span>
<code>the problem of creating something more intelligent than your own species,</code>
<span>创造一个比自己更智能的 物种的问题时，</span>
<code>we might call this "the gorilla problem,"</code>
<span>我们不妨将它称为”大猩猩问题“，</span>
<code>because gorillas' ancestors did this a few million years ago,</code>
<span>因为这正是大猩猩的 祖先们几百万年前所经历的。</span>
<code>and now we can ask the gorillas:</code>
<span>我们今天可以去问大猩猩们：</span>
<code>Was this a good idea?</code>
<span>那么做是不是一个好主意？</span>
<code>So here they are having a meeting to discuss whether it was a good idea,</code>
<span>在这幅图里，大猩猩们正在 开会讨论那么做是不是一个好主意，</span>
<code>and after a little while, they conclude, no,</code>
<span>片刻后他们下定结论，不是的。</span>
<code>this was a terrible idea.</code>
<span>那是一个很糟糕的主意。</span>
<code>Our species is in dire straits.</code>
<span>我们的物种已经奄奄一息了，</span>
<code>In fact, you can see the existential sadness in their eyes.</code>
<span>你都可以从它们的眼神中看到这种忧伤，</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>So this queasy feeling that making something smarter than your own species</code>
<span>所以创造比你自己更聪明的物种，</span>
<code>is maybe not a good idea --</code>
<span>也许不是一个好主意——</span>
<code>what can we do about that?</code>
<span>那我们能做些什么呢？</span>
<code>Well, really nothing, except stop doing AI,</code>
<span>其实没什么能做的， 除了停止研究人工智能，</span>
<code>and because of all the benefits that I mentioned</code>
<span>但因为人工智能能带来 我之前所说的诸多益处，</span>
<code>and because I'm an AI researcher,</code>
<span>也因为我是 人工智能的研究者之一，</span>
<code>I'm not having that.</code>
<span>我可不同意就这么止步。</span>
<code>I actually want to be able to keep doing AI.</code>
<span>实际上，我想继续做人工智能。</span>
<code>So we actually need to nail down the problem a bit more.</code>
<span>所以我们需要把这个问题更细化一点，</span>
<code>What exactly is the problem?</code>
<span>它到底是什么呢？</span>
<code>Why is better AI possibly a catastrophe?</code>
<span>那就是为什么更强大的 人工智能可能会是灾难呢？</span>
<code>So here's another quotation:</code>
<span>再来看这段话：</span>
<code>"We had better be quite sure that the purpose put into the machine</code>
<span>”我们一定得确保我们 给机器输入的目的和价值</span>
<code>is the purpose which we really desire."</code>
<span>是我们确实想要的目的和价值。“</span>
<code>This was said by Norbert Wiener in 1960,</code>
<span>这是诺博特维纳在1960年说的，</span>
<code>shortly after he watched one of the very early learning systems</code>
<span>他说这话时是刚看到 一个早期的学习系统，</span>
<code>learn to play checkers better than its creator.</code>
<span>这个系统在学习如何能把 西洋棋下得比它的创造者更好。</span>
<code>But this could equally have been said</code>
<span>与此如出一辙的一句话，</span>
<code>by King Midas.</code>
<span>迈达斯国王也说过。</span>
<code>King Midas said, "I want everything I touch to turn to gold,"</code>
<span>迈达斯国王说：”我希望 我触碰的所有东西都变成金子。“</span>
<code>and he got exactly what he asked for.</code>
<span>结果他真的获得了点石成金的能力。</span>
<code>That was the purpose that he put into the machine,</code>
<span>那就是他所输入的目的，</span>
<code>so to speak,</code>
<span>从一定程度上说，</span>
<code>and then his food and his drink and his relatives turned to gold</code>
<span>后来他的食物、 他的家人都变成了金子，</span>
<code>and he died in misery and starvation.</code>
<span>他死在痛苦与饥饿之中。</span>
<code>So we'll call this "the King Midas problem"</code>
<span>我们可以把这个问题 叫做”迈达斯问题“，</span>
<code>of stating an objective which is not, in fact,</code>
<span>这个问题是我们阐述的目标，但实际上</span>
<code>truly aligned with what we want.</code>
<span>与我们真正想要的不一致，</span>
<code>In modern terms, we call this "the value alignment problem."</code>
<span>用现代的术语来说， 我们把它称为”价值一致性问题“。</span>
<code>Putting in the wrong objective is not the only part of the problem.</code>
<span>而输入错误的目标 仅仅是问题的一部分。</span>
<code>There's another part.</code>
<span>它还有另一部分。</span>
<code>If you put an objective into a machine,</code>
<span>如果你为机器输入一个目标，</span>
<code>even something as simple as, "Fetch the coffee,"</code>
<span>即便是一个很简单的目标， 比如说”去把咖啡端来“，</span>
<code>the machine says to itself,</code>
<span>机器会对自己说：</span>
<code>"Well, how might I fail to fetch the coffee?</code>
<span>”好吧，那我要怎么去拿咖啡呢？</span>
<code>Someone might switch me off.</code>
<span>说不定有人会把我的电源关掉。</span>
<code>OK, I have to take steps to prevent that.</code>
<span>好吧，那我要想办法 阻止别人把我关掉。</span>
<code>I will disable my 'off' switch.</code>
<span>我得让我的‘关闭’开关失效。</span>
<code>I will do anything to defend myself against interference</code>
<span>我得尽一切可能自我防御， 不让别人干涉我，</span>
<code>with this objective that I have been given."</code>
<span>这都是因为我被赋予的目标。”</span>
<code>So this single-minded pursuit</code>
<span>这种一根筋的思维，</span>
<code>in a very defensive mode of an objective that is, in fact,</code>
<span>以一种十分防御型的 模式去实现某一目标，</span>
<code>not aligned with the true objectives of the human race --</code>
<span>实际上与我们人类最初 想实现的目标并不一致——</span>
<code>that's the problem that we face.</code>
<span>这就是我们面临的问题。</span>
<code>And in fact, that's the high-value takeaway from this talk.</code>
<span>实际上，这就是今天这个演讲的核心。</span>
<code>If you want to remember one thing,</code>
<span>如果你在我的演讲中只记住一件事，</span>
<code>it's that you can't fetch the coffee if you're dead.</code>
<span>那就是：如果你死了， 你就不能去端咖啡了。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>It's very simple. Just remember that. Repeat it to yourself three times a day.</code>
<span>这很简单。记住它就行了。 每天对自己重复三遍。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>And in fact, this is exactly the plot</code>
<span>实际上，这正是电影</span>
<code>of "2001: [A Space Odyssey]"</code>
<span>《2001太空漫步》的剧情。</span>
<code>HAL has an objective, a mission,</code>
<span>HAL有一个目标，一个任务，</span>
<code>which is not aligned with the objectives of the humans,</code>
<span>但这个目标和人类的目标不一致，</span>
<code>and that leads to this conflict.</code>
<span>这就导致了矛盾的产生。</span>
<code>Now fortunately, HAL is not superintelligent.</code>
<span>幸运的是，HAL并不具备超级智能，</span>
<code>He's pretty smart, but eventually Dave outwits him</code>
<span>他挺聪明的，但还是 比不过人类主角戴夫，</span>
<code>and manages to switch him off.</code>
<span>戴夫成功地把HAL关掉了。</span>
<code>But we might not be so lucky.</code>
<span>但我们可能就没有这么幸运了。</span>
<code>So what are we going to do?</code>
<span>那我们应该怎么办呢？</span>
<code>I'm trying to redefine AI</code>
<span>我想要重新定义人工智能，</span>
<code>to get away from this classical notion</code>
<span>远离传统的定义，</span>
<code>of machines that intelligently pursue objectives.</code>
<span>将其仅限定为 机器通过智能去达成目标。</span>
<code>There are three principles involved.</code>
<span>新的定义涉及到三个原则：</span>
<code>The first one is a principle of altruism, if you like,</code>
<span>第一个原则是利他主义原则，</span>
<code>that the robot's only objective</code>
<span>也就是说，机器的唯一目标</span>
<code>is to maximize the realization of human objectives,</code>
<span>就是去最大化地实现人类的目标，</span>
<code>of human values.</code>
<span>人类的价值。</span>
<code>And by values here I don't mean touchy-feely, goody-goody values.</code>
<span>至于价值，我指的不是感情化的价值，</span>
<code>I just mean whatever it is that the human would prefer</code>
<span>而是指人类对生活所向往的，</span>
<code>their life to be like.</code>
<span>无论是什么。</span>
<code>And so this actually violates Asimov's law</code>
<span>这实际上违背了阿西莫夫定律，</span>
<code>that the robot has to protect its own existence.</code>
<span>他指出机器人一定要维护自己的生存。</span>
<code>It has no interest in preserving its existence whatsoever.</code>
<span>但我定义的机器 对维护自身生存毫无兴趣。</span>
<code>The second law is a law of humility, if you like.</code>
<span>第二个原则不妨称之为谦逊原则。</span>
<code>And this turns out to be really important to make robots safe.</code>
<span>这一条对于制造安全的机器十分重要。</span>
<code>It says that the robot does not know</code>
<span>它说的是机器不知道</span>
<code>what those human values are,</code>
<span>人类的价值是什么，</span>
<code>so it has to maximize them, but it doesn't know what they are.</code>
<span>机器知道它需要将人类的价值最大化， 却不知道这价值究竟是什么。</span>
<code>And that avoids this problem of single-minded pursuit</code>
<span>为了避免一根筋地追求</span>
<code>of an objective.</code>
<span>某一目标，</span>
<code>This uncertainty turns out to be crucial.</code>
<span>这种不确定性是至关重要的。</span>
<code>Now, in order to be useful to us,</code>
<span>那机器为了对我们有用，</span>
<code>it has to have some idea of what we want.</code>
<span>它就得掌握一些 关于我们想要什么的信息。</span>
<code>It obtains that information primarily by observation of human choices,</code>
<span>它主要通过观察人类 做的选择来获取这样的信息，</span>
<code>so our own choices reveal information</code>
<span>我们自己做出的选择会包含着</span>
<code>about what it is that we prefer our lives to be like.</code>
<span>关于我们希望我们的生活 是什么样的信息，</span>
<code>So those are the three principles.</code>
<span>这就是三条原则。</span>
<code>Let's see how that applies to this question of:</code>
<span>让我们来看看它们是如何应用到</span>
<code>"Can you switch the machine off?" as Turing suggested.</code>
<span>像图灵说的那样， “将机器关掉”这个问题上来。</span>
<code>So here's a PR2 robot.</code>
<span>这是一个PR2机器人。</span>
<code>This is one that we have in our lab,</code>
<span>我们实验室里有一个。</span>
<code>and it has a big red "off" switch right on the back.</code>
<span>它的背面有一个大大的红色的开关。</span>
<code>The question is: Is it going to let you switch it off?</code>
<span>那问题来了：它会让你把它关掉吗？</span>
<code>If we do it the classical way,</code>
<span>如果我们按传统的方法，</span>
<code>we give it the objective of, "Fetch the coffee, I must fetch the coffee,</code>
<span>给它一个目标，让它拿咖啡， 它会想：”我必须去拿咖啡，</span>
<code>I can't fetch the coffee if I'm dead,"</code>
<span>但我死了就不能拿咖啡了。“</span>
<code>so obviously the PR2 has been listening to my talk,</code>
<span>显然PR2听过我的演讲了，</span>
<code>and so it says, therefore, "I must disable my 'off' switch,</code>
<span>所以它说：”我必须让我的开关失灵，</span>
<code>and probably taser all the other people in Starbucks</code>
<span>可能还要把那些在星巴克里，</span>
<code>who might interfere with me."</code>
<span>可能干扰我的人都电击一下。“</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>So this seems to be inevitable, right?</code>
<span>这看起来必然会发生，对吗？</span>
<code>This kind of failure mode seems to be inevitable,</code>
<span>这种失败看起来是必然的，</span>
<code>and it follows from having a concrete, definite objective.</code>
<span>因为机器人在遵循 一个十分确定的目标。</span>
<code>So what happens if the machine is uncertain about the objective?</code>
<span>那如果机器对目标 不那么确定会发生什么呢？</span>
<code>Well, it reasons in a different way.</code>
<span>那它的思路就不一样了。</span>
<code>It says, "OK, the human might switch me off,</code>
<span>它会说：”好的，人类可能会把我关掉，</span>
<code>but only if I'm doing something wrong.</code>
<span>但只在我做错事的时候。</span>
<code>Well, I don't really know what wrong is,</code>
<span>我不知道什么是错事，</span>
<code>but I know that I don't want to do it."</code>
<span>但我知道我不该做那些事。”</span>
<code>So that's the first and second principles right there.</code>
<span>这就是第一和第二原则。</span>
<code>"So I should let the human switch me off."</code>
<span>“那我就应该让人类把我关掉。”</span>
<code>And in fact you can calculate the incentive that the robot has</code>
<span>事实上你可以计算出机器人</span>
<code>to allow the human to switch it off,</code>
<span>让人类把它关掉的动机，</span>
<code>and it's directly tied to the degree</code>
<span>而且这个动机是</span>
<code>of uncertainty about the underlying objective.</code>
<span>与对目标的不确定程度直接相关的。</span>
<code>And then when the machine is switched off,</code>
<span>当机器被关闭后，</span>
<code>that third principle comes into play.</code>
<span>第三条原则就起作用了。</span>
<code>It learns something about the objectives it should be pursuing,</code>
<span>机器开始学习它所追求的目标，</span>
<code>because it learns that what it did wasn't right.</code>
<span>因为它知道它刚做的事是不对的。</span>
<code>In fact, we can, with suitable use of Greek symbols,</code>
<span>实际上，我们可以用希腊字母</span>
<code>as mathematicians usually do,</code>
<span>就像数学家们经常做的那样，</span>
<code>we can actually prove a theorem</code>
<span>直接证明这一定理，</span>
<code>that says that such a robot is provably beneficial to the human.</code>
<span>那就是这样的一个机器人 对人们是绝对有利的。</span>
<code>You are provably better off with a machine that's designed in this way</code>
<span>可以证明我们的生活 有如此设计的机器人会变得</span>
<code>than without it.</code>
<span>比没有这样的机器人更好。</span>
<code>So this is a very simple example, but this is the first step</code>
<span>这是一个很简单的例子，但这只是</span>
<code>in what we're trying to do with human-compatible AI.</code>
<span>我们尝试实现与人类 兼容的人工智能的第一步。</span>
<code>Now, this third principle,</code>
<span>现在来看第三个原则。</span>
<code>I think is the one that you're probably scratching your head over.</code>
<span>我知道你们可能正在 为这一个原则而大伤脑筋。</span>
<code>You're probably thinking, "Well, you know, I behave badly.</code>
<span>你可能会想：“你知道， 我有时不按规矩办事。</span>
<code>I don't want my robot to behave like me.</code>
<span>我可不希望我的机器人 像我一样行事。</span>
<code>I sneak down in the middle of the night and take stuff from the fridge.</code>
<span>我有时大半夜偷偷摸摸地 从冰箱里找东西吃，</span>
<code>I do this and that."</code>
<span>诸如此类的事。”</span>
<code>There's all kinds of things you don't want the robot doing.</code>
<span>有各种各样的事你是 不希望机器人去做的。</span>
<code>But in fact, it doesn't quite work that way.</code>
<span>但实际上并不一定会这样。</span>
<code>Just because you behave badly</code>
<span>仅仅是因为你表现不好，</span>
<code>doesn't mean the robot is going to copy your behavior.</code>
<span>并不代表机器人就会复制你的行为。</span>
<code>It's going to understand your motivations and maybe help you resist them,</code>
<span>它会去尝试理解你做事的动机， 而且可能会在合适的情况下制止你去做</span>
<code>if appropriate.</code>
<span>那些不该做的事。</span>
<code>But it's still difficult.</code>
<span>但这仍然十分困难。</span>
<code>What we're trying to do, in fact,</code>
<span>实际上，我们在做的是</span>
<code>is to allow machines to predict for any person and for any possible life</code>
<span>让机器去预测任何一个人， 在他们的任何一种</span>
<code>that they could live,</code>
<span>可能的生活中</span>
<code>and the lives of everybody else:</code>
<span>以及别人的生活中，</span>
<code>Which would they prefer?</code>
<span>他们会更倾向于哪一种？</span>
<code>And there are many, many difficulties involved in doing this;</code>
<span>这涉及到诸多困难；</span>
<code>I don't expect that this is going to get solved very quickly.</code>
<span>我不认为这会很快地就被解决。</span>
<code>The real difficulties, in fact, are us.</code>
<span>实际上，真正的困难是我们自己。</span>
<code>As I have already mentioned, we behave badly.</code>
<span>就像我刚说的那样， 我们做事不守规矩，</span>
<code>In fact, some of us are downright nasty.</code>
<span>我们中有的人甚至行为肮脏。</span>
<code>Now the robot, as I said, doesn't have to copy the behavior.</code>
<span>就像我说的， 机器人并不会复制那些行为，</span>
<code>The robot does not have any objective of its own.</code>
<span>机器人没有自己的目标，</span>
<code>It's purely altruistic.</code>
<span>它是完全无私的。</span>
<code>And it's not designed just to satisfy the desires of one person, the user,</code>
<span>它的设计不是去满足 某一个人、一个用户的欲望，</span>
<code>but in fact it has to respect the preferences of everybody.</code>
<span>而是去尊重所有人的意愿。</span>
<code>So it can deal with a certain amount of nastiness,</code>
<span>所以它能对付一定程度的肮脏行为。</span>
<code>and it can even understand that your nastiness, for example,</code>
<span>它甚至能理解你的不端行为，比如说</span>
<code>you may take bribes as a passport official</code>
<span>假如你是一个边境护照官员， 很可能收取贿赂，</span>
<code>because you need to feed your family and send your kids to school.</code>
<span>因为你得养家、 得供你的孩子们上学。</span>
<code>It can understand that; it doesn't mean it's going to steal.</code>
<span>机器人能理解这一点， 它不会因此去偷，</span>
<code>In fact, it'll just help you send your kids to school.</code>
<span>它反而会帮助你去供孩子们上学。</span>
<code>We are also computationally limited.</code>
<span>我们的计算能力也是有限的。</span>
<code>Lee Sedol is a brilliant Go player,</code>
<span>李世石是一个杰出的围棋大师，</span>
<code>but he still lost.</code>
<span>但他还是输了。</span>
<code>So if we look at his actions, he took an action that lost the game.</code>
<span>如果我们看他的行动， 他最终输掉了棋局。</span>
<code>That doesn't mean he wanted to lose.</code>
<span>但这不意味着他想要输。</span>
<code>So to understand his behavior,</code>
<span>所以要理解他的行为，</span>
<code>we actually have to invert through a model of human cognition</code>
<span>我们得从人类认知模型来反过来想，</span>
<code>that includes our computational limitations -- a very complicated model.</code>
<span>这包含了我们的计算能力限制， 是一个很复杂的模型，</span>
<code>But it's still something that we can work on understanding.</code>
<span>但仍然是我们可以尝试去理解的。</span>
<code>Probably the most difficult part, from my point of view as an AI researcher,</code>
<span>可能对于我这样一个 人工智能研究人员来说最大的困难，</span>
<code>is the fact that there are lots of us,</code>
<span>是我们彼此各不相同。</span>
<code>and so the machine has to somehow trade off, weigh up the preferences</code>
<span>所以机器必须想办法去判别衡量</span>
<code>of many different people,</code>
<span>不同人的不同需求，</span>
<code>and there are different ways to do that.</code>
<span>而又有众多方法去做这样的判断。</span>
<code>Economists, sociologists, moral philosophers have understood that,</code>
<span>经济学家、社会学家、 哲学家都理解这一点，</span>
<code>and we are actively looking for collaboration.</code>
<span>我们正在积极地去寻求合作。</span>
<code>Let's have a look and see what happens when you get that wrong.</code>
<span>让我们来看看如果我们 把这一步弄错了会怎么样。</span>
<code>So you can have a conversation, for example,</code>
<span>举例来说，你可能会 与你的人工智能助理，</span>
<code>with your intelligent personal assistant</code>
<span>有这样的对话：</span>
<code>that might be available in a few years' time.</code>
<span>这样的人工智能可能几年内就会出现，</span>
<code>Think of a Siri on steroids.</code>
<span>可以把它想做加强版的Siri。</span>
<code>So Siri says, "Your wife called to remind you about dinner tonight."</code>
<span>Siri对你说：“你的妻子打电话 提醒你今晚要跟她共进晚餐。”</span>
<code>And of course, you've forgotten. "What? What dinner?</code>
<span>而你呢，自然忘了这回事： “什么？什么晚饭？</span>
<code>What are you talking about?"</code>
<span>你在说什么？”</span>
<code>"Uh, your 20th anniversary at 7pm."</code>
<span>“啊，你们晚上7点， 庆祝结婚20周年纪念日。”</span>
<code>"I can't do that. I'm meeting with the secretary-general at 7:30.</code>
<span>“我可去不了。 我约了晚上7点半见领导。</span>
<code>How could this have happened?"</code>
<span>怎么会这样呢？”</span>
<code>"Well, I did warn you, but you overrode my recommendation."</code>
<span>“呃，我可是提醒过你的， 但你不听我的建议。”</span>
<code>"Well, what am I going to do? I can't just tell him I'm too busy."</code>
<span>“我该怎么办呢？我可不能 跟领导说我有事，没空见他。”</span>
<code>"Don't worry. I arranged for his plane to be delayed."</code>
<span>“别担心。我已经安排了， 让他的航班延误。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>"Some kind of computer malfunction."</code>
<span>“像是因为某种计算机故障那样。”</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>"Really? You can do that?"</code>
<span>“真的吗？这个你也能做到？”</span>
<code>"He sends his profound apologies</code>
<span>“领导很不好意思，跟你道歉，</span>
<code>and looks forward to meeting you for lunch tomorrow."</code>
<span>并且告诉你明天 中午午饭不见不散。”</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>So the values here -- there's a slight mistake going on.</code>
<span>这里就有一个小小的问题。</span>
<code>This is clearly following my wife's values</code>
<span>这显然是在遵循我妻子的价值论，</span>
<code>which is "Happy wife, happy life."</code>
<span>那就是“老婆开心，生活舒心”。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>It could go the other way.</code>
<span>它也有可能发展成另一种情况。</span>
<code>You could come home after a hard day's work,</code>
<span>你忙碌一天，回到家里，</span>
<code>and the computer says, "Long day?"</code>
<span>电脑对你说：“像是繁忙的一天啊？”</span>
<code>"Yes, I didn't even have time for lunch."</code>
<span>“是啊，我连午饭都没来得及吃。”</span>
<code>"You must be very hungry."</code>
<span>“那你一定很饿了吧。”</span>
<code>"Starving, yeah. Could you make some dinner?"</code>
<span>“快饿晕了。你能做点晚饭吗？”</span>
<code>"There's something I need to tell you."</code>
<span>“有一件事我得告诉你。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>"There are humans in South Sudan who are in more urgent need than you."</code>
<span>”南苏丹的人们可比你更需要照顾。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>"So I'm leaving. Make your own dinner."</code>
<span>“所以我要离开了。 你自己做饭去吧。”</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>So we have to solve these problems,</code>
<span>我们得解决这些问题，</span>
<code>and I'm looking forward to working on them.</code>
<span>我也很期待去解决。</span>
<code>There are reasons for optimism.</code>
<span>我们有理由感到乐观。</span>
<code>One reason is,</code>
<span>理由之一是</span>
<code>there is a massive amount of data.</code>
<span>我们有大量的数据，</span>
<code>Because remember -- I said they're going to read everything</code>
<span>记住，我说过机器将能够阅读一切</span>
<code>the human race has ever written.</code>
<span>人类所写下来的东西，</span>
<code>Most of what we write about is human beings doing things</code>
<span>而我们写下的大多数是 我们做的什么事情，</span>
<code>and other people getting upset about it.</code>
<span>以及其他人对此有什么意见。</span>
<code>So there's a massive amount of data to learn from.</code>
<span>所以机器可以从大量的数据中去学习。</span>
<code>There's also a very strong economic incentive</code>
<span>同时从经济的角度， 我们也有足够的动机</span>
<code>to get this right.</code>
<span>去把这件事做对。</span>
<code>So imagine your domestic robot's at home.</code>
<span>想象一下，你家里有个居家机器人，</span>
<code>You're late from work again and the robot has to feed the kids,</code>
<span>而你又得加班， 机器人得给孩子们做饭,</span>
<code>and the kids are hungry and there's nothing in the fridge.</code>
<span>孩子们很饿， 但冰箱里什么都没有。</span>
<code>And the robot sees the cat.</code>
<span>然后机器人看到了家里的猫，</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>And the robot hasn't quite learned the human value function properly,</code>
<span>机器人还没学透人类的价值论，</span>
<code>so it doesn't understand</code>
<span>所以它不知道</span>
<code>the sentimental value of the cat outweighs the nutritional value of the cat.</code>
<span>猫的感情价值 大于猫的营养价值。</span>
<code>(Laughter)</code>
<span>（笑声）</span>
<code>So then what happens?</code>
<span>接下来会发生什么？</span>
<code>Well, it happens like this:</code>
<span>差不多是这样的：</span>
<code>"Deranged robot cooks kitty for family dinner."</code>
<span>头版头条：“疯狂的机器人 把猫煮了给主人当晚饭！”</span>
<code>That one incident would be the end of the domestic robot industry.</code>
<span>这一个事故就足以结束 整个居家机器人产业。</span>
<code>So there's a huge incentive to get this right</code>
<span>所以我们有足够的动机在我们实现</span>
<code>long before we reach superintelligent machines.</code>
<span>超级智能机器让它更加完善。</span>
<code>So to summarize:</code>
<span>总结来说：</span>
<code>I'm actually trying to change the definition of AI</code>
<span>我想要改变人工智能的定义，</span>
<code>so that we have provably beneficial machines.</code>
<span>让我们可以证明机器对我们是有利的。</span>
<code>And the principles are:</code>
<span>这三个原则是：</span>
<code>machines that are altruistic,</code>
<span>机器是利他的，</span>
<code>that want to achieve only our objectives,</code>
<span>只想着实现我们的目标，</span>
<code>but that are uncertain about what those objectives are,</code>
<span>但它不确定我们的目标是什么，</span>
<code>and will watch all of us</code>
<span>所以它会观察我们，</span>
<code>to learn more about what it is that we really want.</code>
<span>从中学习我们想要的究竟是什么。</span>
<code>And hopefully in the process, we will learn to be better people.</code>
<span>希望在这个过程中， 我们也能学会成为更好的人。</span>
<code>Thank you very much.</code>
<span>谢谢大家。</span>
<code>(Applause)</code>
<span>（掌声）</span>
<code>Chris Anderson: So interesting, Stuart.</code>
<span>克里斯安德森： 非常有意思，斯图尔特。</span>
<code>We're going to stand here a bit because I think they're setting up</code>
<span>我们趁着工作人员 为下一位演讲者布置的时候</span>
<code>for our next speaker.</code>
<span>来简单聊几句。</span>
<code>A couple of questions.</code>
<span>我有几个问题。</span>
<code>So the idea of programming in ignorance seems intuitively really powerful.</code>
<span>从直觉上来看，将无知编入到程序中 似乎是一个很重要的理念，</span>
<code>As you get to superintelligence,</code>
<span>当你要实现超级智能时，</span>
<code>what's going to stop a robot</code>
<span>什么能阻止机器人？</span>
<code>reading literature and discovering this idea that knowledge</code>
<span>当它在阅读和学习的过程中发现，</span>
<code>is actually better than ignorance</code>
<span>知识比无知更强大，</span>
<code>and still just shifting its own goals and rewriting that programming?</code>
<span>然后就改变它的目标 去重新编写程序呢？</span>
<code>Stuart Russell: Yes, so we want it to learn more, as I said,</code>
<span>斯图尔特拉塞尔：是的， 我们想要它去学习，就像我说的，</span>
<code>about our objectives.</code>
<span>学习我们的目标。</span>
<code>It'll only become more certain as it becomes more correct,</code>
<span>它只有在理解得越来越正确的时候， 才会变得更确定，</span>
<code>so the evidence is there</code>
<span>我们有证据显示，</span>
<code>and it's going to be designed to interpret it correctly.</code>
<span>它的设计使它能按正确的方式理解。</span>
<code>It will understand, for example, that books are very biased</code>
<span>比如说，它能够理解书中的论证是</span>
<code>in the evidence they contain.</code>
<span>带有非常强的偏见的。</span>
<code>They only talk about kings and princes</code>
<span>书中只会讲述国王、王子</span>
<code>and elite white male people doing stuff.</code>
<span>和那些精英白人男性做的事。</span>
<code>So it's a complicated problem,</code>
<span>这是一个复杂的问题，</span>
<code>but as it learns more about our objectives</code>
<span>但当它更深入地学习我们的目标时，</span>
<code>it will become more and more useful to us.</code>
<span>它就变得对我们更有用。</span>
<code>CA: And you couldn't just boil it down to one law,</code>
<span>CA：那你不能把这些 都集中在一条准则里吗？</span>
<code>you know, hardwired in:</code>
<span>把这样的命令写在它的程序里：</span>
<code>"if any human ever tries to switch me off,</code>
<span>“如果人类什么时候想把我关掉，</span>
<code>I comply. I comply."</code>
<span>我服从。我服从。”</span>
<code>SR: Absolutely not.</code>
<span>SR：绝对不行，</span>
<code>That would be a terrible idea.</code>
<span>那将是一个很糟糕的主意。</span>
<code>So imagine that you have a self-driving car</code>
<span>试想一下，你有一辆无人驾驶汽车，</span>
<code>and you want to send your five-year-old</code>
<span>你想让它送你五岁的孩子</span>
<code>off to preschool.</code>
<span>去上学。</span>
<code>Do you want your five-year-old to be able to switch off the car</code>
<span>你希望你五岁的孩子 能在汽车运行过程中</span>
<code>while it's driving along?</code>
<span>将它关闭吗？</span>
<code>Probably not.</code>
<span>应该不会吧。</span>
<code>So it needs to understand how rational and sensible the person is.</code>
<span>它得理解下指令的人有多理智， 是不是讲道理。</span>
<code>The more rational the person,</code>
<span>这个人越理智，</span>
<code>the more willing you are to be switched off.</code>
<span>它就越愿意自己被关掉。</span>
<code>If the person is completely random or even malicious,</code>
<span>如果这个人是完全思绪混乱 或者甚至是有恶意的，</span>
<code>then you're less willing to be switched off.</code>
<span>那你就不愿意它被关掉。</span>
<code>CA: All right. Stuart, can I just say,</code>
<span>CA：好吧。斯图尔特，我得说</span>
<code>I really, really hope you figure this out for us.</code>
<span>我真的希望你为我们 能把这一切研究出来，</span>
<code>Thank you so much for that talk. That was amazing.</code>
<span>很感谢你的演讲，太精彩了。</span>
<code>SR: Thank you.</code>
<span>SR：谢谢。</span>
<code>(Applause)</code>
<span>（掌声）</span></p><center><a style="color: rgb(254,17,130)" href="https://icp.gov.moe/?keyword=20223985" target="_blank">萌ICP备20223985号</a></center></div></div>
</body>
</html>